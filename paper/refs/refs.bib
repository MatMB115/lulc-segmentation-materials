@article{wisserGlobalIrrigationWater2008,
  title = {Global Irrigation Water Demand: {{Variability}} and Uncertainties Arising from Agricultural and Climate Data Sets},
  shorttitle = {Global Irrigation Water Demand},
  author = {Wisser, Dominik and Frolking, Steve and Douglas, Ellen M. and Fekete, Balazs M. and Vörösmarty, Charles J. and Schumann, Andreas H.},
  year={2008},
  date = {2008-12},
  journal = {Geophysical Research Letters},
  shortjournal = {Geophysical Research Letters},
  volume = {35},
  number = {24},
  pages = {2008GL035296},
  issn = {0094-8276, 1944-8007},
  doi = {10.1029/2008GL035296},
  url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2008GL035296},
  urldate = {2025-06-13},
  abstract = {Agricultural water use accounts for around 70\% of the total water that is withdrawn from surface water and groundwater. We use a new, gridded, global‐scale water balance model to estimate interannual variability in global irrigation water demand arising from climate data sets and uncertainties arising from agricultural and climate data sets. We used contemporary maps of irrigation and crop distribution, and so do not account for variability or trends in irrigation area or cropping. We used two different global maps of irrigation and two different reconstructions of daily weather 1963–2002. Simulated global irrigation water demand varied by ∼30\%, depending on irrigation map or weather data. The combined effect of irrigation map and weather data generated a global irrigation water use range of 2200 to 3800 km               3               a               −1               . Weather driven variability in global irrigation was generally less than ±300 km               3               a               −1               , globally ({$<$}∼10\%), but could be as large as ±70\% at the national scale.},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/87LZ3HN9/Wisser et al. - 2008 - Global irrigation water demand Variability and uncertainties arising from agricultural and climate.pdf}
}

@article{fanEvaluatingCultivatedLand2020,
  title = {Evaluating Cultivated Land Stability during the Growing Season Based on Precipitation in the {{Horqin Sandy Land}}, {{China}}},
  author = {Fan, Jiaqi and Wang, Lu and Qin, Jiaxing and Zhang, Fengrong and Xu, Yan},
  year = {2020},
  month = dec,
  journal = {Journal of Environmental Management},
  volume = {276},
  pages = {111269},
  issn = {0301-4797},
  doi = {10.1016/j.jenvman.2020.111269},
  urldate = {2025-06-13},
  abstract = {As a fundamental resource for human beings, cultivated land contributes significantly to the sustainable development of society. Investigating cultivated land stability in semiarid areas with a fragile ecology is essential for stabilizing agricultural production and preserving environmental security. The objective of this study was to evaluate cultivated land stability by combining the growth root normalized difference vegetation index (GRNDVI) and precipitation during the crop growing season from 2015 to 2019 in the Horqin Zuoyihou Banner. The productivity of cultivated land was categorized into five levels by the relative criterion, and the minimum productivity level was chosen to represent the stability level. The results showed that a variation in precipitation was evident across both years and crop growing seasons; approximately 66.78\% of the cultivated land was classified as moderately stable, 6.55\% was classified as highly stable, 22.14\% was classified as marginally stable, 0.91\% was classified as extremely stable, and 3.62\% was classified as unstable. Extremely and highly stable cultivated lands were dominant at the eastern and southern ends of the region, and marginal and unstable cultivated lands were principally present in the west and north while moderately stable land was distributed extensively. Cultivated land stability was affected substantially by water availability and topography, indicating that cultivated land with high levels of stability was distributed more in areas with abundant water and flat terrain. Marginally stable and unstable cultivated lands should be returned to their previous vegetation covers, with priority given to planting appropriate sandy plants to restore ecological integrity. Such evaluation outcomes are meaningful for optimizing the distribution of cultivated land and facilitating the sustainable utilization of land resources.},
  keywords = {Crop growing season,Cultivated land stability,Horqin sandy land,Precipitation,Sustainable development},
  file = {/home/maysu-wk/Zotero/storage/ECMKM8KY/Fan et al. - 2020 - Evaluating cultivated land stability during the growing season based on precipitation in the Horqin.pdf;/home/maysu-wk/Zotero/storage/5GA5DRUU/S0301479720311932.html}
}
@article{pangSpatialTemporalDifferentiation2024,
  title = {Spatial--{{Temporal Differentiation}} and {{Driving Factors}} of {{Cultivated Land Use Transition}} in {{Sino}}--{{Vietnamese Border Areas}}},
  author = {Pang, Xiaofei and Xie, Binggeng and Lu, Rucheng and Zhang, Xuemao and Xie, Jing and Wei, Shaoyin},
  year = {2024},
  month = feb,
  journal = {Land},
  volume = {13},
  number = {2},
  pages = {165},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2073-445X},
  doi = {10.3390/land13020165},
  urldate = {2025-06-13},
  abstract = {Understanding the transformation of cultivated land use is crucial for advancing sustainable development goals related to food security. However, in mountainous regions, there is a lack of comprehensive studies that fully account for the diverse factors influencing cultivated land use transformation. This study aims to elucidate the temporal and spatial dynamics of cultivated land resource transformation in the mountainous Sino--Vietnam border area, uncover its underlying driving mechanisms, and offer insights for safeguarding cultivated land, promoting economic development, ensuring homeland security, enhancing ecological security, and bolstering border stability and prosperity. To investigate the cultivated land use transformation pattern in the Sino--Vietnam border area from 2000 to 2020, we employed kernel density estimation and geo-information spectra. Additionally, we developed a comprehensive driving force system tailored to the unique characteristics of cultivated land use in the border region. We applied a spatial econometric model to dissect the driving mechanisms governing cultivated land use transformation. Our findings revealed several key insights: (1) The density of cultivated land in the Sino--Vietnam border area exhibited an initial increase followed by a decrease. Notably, the transformation of cultivated land was most prominent in the eastern plains, intensifying over time. (2) The predominant type of transformation in the Sino--Vietnamese border area revolved around the mutual conversion of cultivated land and woodland, with the mutual conversion of cultivated land and grassland ranking second. (3) Against the backdrop of urban--rural integration, the transformation of cultivated land use at the border progressed from a phase of rapid decline to a phase of slower decline. (4) The transformation of cultivated land was influenced by a complex interplay of socio-economic factors, natural environmental conditions, policy management, and transportation infrastructure. The relative importance of these factors in driving cultivated land use transformation varied significantly across different time periods. In light of these findings, we recommend promoting agricultural modernization and industrialization in the Sino--Vietnamese border areas. It is essential to consider the region's distinct cultivated land characteristics, implement tailored land policies, and develop diversified strategies for the utilization and management of cultivated land. Furthermore, harnessing land resources to stimulate economic development should be a focal point of future initiatives in the area.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {cultivated land use transition,driving mechanism,Sino-Vietnamese border areas,spatial econometric model,spatio-temporal evolution},
  file = {/home/maysu-wk/Zotero/storage/Z43IVY2P/Pang et al. - 2024 - Spatial–Temporal Differentiation and Driving Factors of Cultivated Land Use Transition in Sino–Vietn.pdf}
}
@article{wangEditorialSustainableCultivated2023,
  title = {Editorial: {{Sustainable}} Cultivated Land Use and Management},
  shorttitle = {Editorial},
  author = {Wang, Yongsheng and {Lopez-Carr}, David and Gong, Jianzhou and Gao, Jinlong},
  year = {2023},
  month = mar,
  journal = {Frontiers in Environmental Science},
  volume = {11},
  publisher = {Frontiers},
  issn = {2296-665X},
  doi = {10.3389/fenvs.2023.1162769},
  urldate = {2025-06-13},
  abstract = {Cultivated land is an important resource for human survival and development, making its protection one of the highest priorities for the globe. Healthy, ecological, and highly efficient cultivated lands form the basis of modern agriculture and then the foundation of food security. In recent decades, rapid urbanization and industrialization have promoted economic development and improved livelihoods worldwide, leading to diversified food and commodity production and consumption. Notwithstanding, land degradation problems including abandonment, pollution, and erosion have emerged during the land use transition, posing challenges to both the ecosystem service supply and Sustainable Development Goals (SDGs). Especially, intensive cultivated land use and overwhelming dependence on fertilizers and pesticides have led to agricultural non-point source pollution, and greenhouse gas emissions, which further challenged the ecological environment and sustainable development.Within this research topic, we aim to present a collection of original articles that address the theories, practices, and models for sustainable cultivated land use and management. This research topic collected a total of 17 papers, which can be largely divided into the following three areas.(1) Land use and ecosystem service, a total of six papers, including land use transitions and their influence on spatiotemporal patterns of ecosystem service and their contribution on sustainable development goals.(2) Cultivated land use, a total of five papers, including spatiotemporal changes and driving forces, vulnerability and planting pattern change.(3) Cultivated land management, a total of six papers, including fragmentation identification, productivity, optimization, and fertilization management. The 17 papers in this Research Topic use field experiment, regional investigation, model simulation and prediction, and provide interesting and meaningful results and thought-provoking discussions on land use and ecosystem services, cultivated land use, and cultivated land management. Many thanks for all the authors and reviewers who contributed to this Research Topic.Together these articles provide valuable insight into the discussion of sustainable cultivated land use and management, and create the exciting interactive for future research.},
  langid = {english},
  keywords = {Cultivated land,ecosystem service,food secuity,Land use transition,Sustainable use and management},
  file = {/home/maysu-wk/Zotero/storage/LYZYL3BZ/Wang et al. - 2023 - Editorial Sustainable cultivated land use and management.pdf}
}
@article{muellerClosingYieldGaps2012,
  title = {Closing Yield Gaps through Nutrient and Water Management},
  author = {Mueller, Nathaniel D. and Gerber, James S. and Johnston, Matt and Ray, Deepak K. and Ramankutty, Navin and Foley, Jonathan A.},
  year = {2012},
  month = oct,
  journal = {Nature},
  volume = {490},
  number = {7419},
  pages = {254--257},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature11420},
  urldate = {2025-06-13},
  abstract = {Global yields of major crops are analysed using climate, irrigation and new nutrient data to show that large production increases are possible from closing yield gaps to 100\% of attainable yields, and that changes in management practices needed to close yield gaps vary considerably by region and current intensity.},
  copyright = {2012 Springer Nature Limited},
  langid = {english},
  keywords = {Environmental economics,Environmental sciences},
  file = {/home/maysu-wk/Zotero/storage/G3X7AQ89/Mueller et al. - 2012 - Closing yield gaps through nutrient and water management.pdf}
}
@article{miaoSNUNet3FullScaleConnected2024,
  title = {{{SNUNet3}}+: {{A Full-Scale Connected Siamese Network}} and a {{Dataset}} for {{Cultivated Land Change Detection}} in {{High-Resolution Remote-Sensing Images}}},
  shorttitle = {{{SNUNet3}}+},
  author = {Miao, Lizhi and Li, Xinting and Zhou, Xinxin and Yao, Ling and Deng, Yamei and Hang, Tian and Zhou, Yuchao and Yang, Haozhou},
  year = {2024},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  volume = {62},
  pages = {1--18},
  issn = {1558-0644},
  doi = {10.1109/TGRS.2023.3344284},
  urldate = {2025-06-13},
  abstract = {The decline of cultivated land significantly threatens the food supply. In recent years, remote sensing (RS) change detection emerged as a valuable tool for monitoring nonagriculturalization. However, existing deep learning (DL) methods for change detection suffer from the problem of inadequate utilization of feature information during image feature extraction, leading to noisy or inaccurate change maps. To address these challenges, we propose a Siamese network based on full-scale connected UNet (SNUNet3+), whose encoder extracts features from the original images at various levels. Then, it merges all fine-grained spatial information and coarse-grained semantic information into the decoder through full-scale skip connections to obtain the feature maps with complete information. The spatial and channel squeeze and excitation (scSE) attention mechanism is embedded within the decoder subnetwork to enhance the discriminative power of the features. In addition, a deep supervision module is introduced to improve the feature learning capability of the hidden layers and the quality of features. Moreover, accurate cultivated land change detection remains challenging because of the lack of fine-grained detection datasets. To enable the proposed method to achieve cultivated land change detection, we produced a cultivated land change detection dataset containing 5170 pairs of 256 {\textbackslash}times 256 bitemporal images with a spatial resolution of 1 m. The effectiveness and performance of the proposed method are evaluated on three high-resolution RS change detection datasets. Extensive experimental results show that the proposed method outperforms other state-of-the-art methods, achieving the highest F1 -score of 72.90\%, 90.36\%, and 96.64\% on the CLCD dataset, LEVIR-CD dataset, and PX-CLCD dataset, respectively.},
  keywords = {Change detection,Convolutional neural networks,Decoding,Deep learning,deep learning (DL),Feature extraction,nonagriculturalization of cultivated land,Remote sensing,remote sensing (RS),Task analysis,Transformers,UNet3+},
  file = {/home/maysu-wk/Zotero/storage/79KC53H7/Miao et al. - 2024 - SNUNet3+ A Full-Scale Connected Siamese Network and a Dataset for Cultivated Land Change Detection.pdf}
}
@article{riehleRobustIndexbasedSemantic2020,
  title = {Robust Index-Based Semantic Plant/Background Segmentation for {{RGB-}} Images},
  author = {Riehle, Daniel and Reiser, David and Griepentrog, Hans W.},
  year = {2020},
  month = feb,
  journal = {Computers and Electronics in Agriculture},
  volume = {169},
  pages = {105201},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2019.105201},
  urldate = {2025-06-13},
  abstract = {Plant/background segmentation is a key component of digital image analysis in agriculture. It can be used for yield prediction models, crop growth, disease diagnosis and automated navigation tasks. In particular, well-known segmentation methods are strongly influenced by changing light conditions during image acquisition as well as different color variations of plants and the background in the scene. In this work, an algorithm was developed and evaluated which can perform robust automated plant/background segmentation under varying capture conditions such as overexposure or underexposure along with diverse colors of the crop and background. The algorithm relies on an index-based method for approximate pre-segmentation and uses this first approximation to calculate the threshold value for a segmentation using a color space model. The performance of the algorithm was evaluated with 200 images from 4 different cameras and settings. Furthermore, the algorithm quality was compared with existing index-based segmentation methods such as the excess green index, the excess red index, excess green minus excess red index. All indices were combined with Otsu thresholding. The results showed that the novel approach has a more robust performance and is more reliable than the other index-based segmentation methods. The investigations showed excellent results of the algorithm using the CieLab color space with semantic plant segmentation accuracies of 97.4\%.},
  keywords = {CieLab,Index-based segmentation,Otsu,Plant/soil segmentation,Semantic segmentation},
  file = {/home/maysu-wk/Zotero/storage/GP2KHCRE/Riehle et al. - 2020 - Robust index-based semantic plantbackground segmentation for RGB- images.pdf;/home/maysu-wk/Zotero/storage/WMT3HER3/S0168169919314346.html}
}
@misc{INPE2019,
  title = {Satellite Monitoring of Deforestation of the Brazilian Amazon Forest},
  author = {{INPE}},
  year = {2019}
}

@article{deoliveiraMethodologyDataFusion2020,
  title = {Methodology of {{Data Fusion Using Deep Learning}} for {{Semantic Segmentation}} of {{Land Types}} in the {{Amazon}}},
  author = {De Oliveira, Joel Parente and Costa, Marly Guimaraes Fernandes and Filho, Cicero Ferreira Fernandes Costa},
  year = {2020},
  journal = {IEEE Access},
  volume = {8},
  pages = {187864--187875},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3031533},
  urldate = {2025-06-13},
  abstract = {This study proposes a methodology using deep learning and a multi-resolution segmentation algorithm to perform the semantic segmentation of remote sensing images. Initially the image is segmented using a CNN, and then an image with homogeneous regions is generated using a multi-resolution segmentation algorithm. Finally, a data fusion process is performed with these two images, generating the final classified image. The field of study was the Brazilian Amazon region. The proposed methodology classifies images in the following classes: forest, pasture and agriculture. The input data used were LANDSAT-8/OLI images. The reference data were extracted from the results of the TerraClass project in 2014. Two datasets were evaluated: the first with six bands and the second with three bands. Three CNN architectures were evaluated together with three optimization methods: SGDM, ADAM, and RMSProp and the dropout and L2 regularization methods as methods for generalization improvement. The best model, CNN + optimization method + technique for generalization improvement, evaluated in the validation set, was submitted to a 5-fold cross validation methodology, and the results were compared with pre-trained networks using the learning transfer methodology; in this case the networks used for comparison were ResNet50, InceptionResnetv2, MobileNetv2 and Xception. The proposed methodology was evaluated through image segmentation of some regions of the Amazon. Finally, the proposed methodology was evaluated in regions used by other authors. The accuracy values obtained for the images evaluated were over 99\%.},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/SHRS2MKK/De Oliveira et al. - 2020 - Methodology of Data Fusion Using Deep Learning for Semantic Segmentation of Land Types in the Amazon.pdf}
}
@article{luoSemanticSegmentationAgricultural2024,
  title = {Semantic Segmentation of Agricultural Images: {{A}} Survey},
  shorttitle = {Semantic Segmentation of Agricultural Images},
  author = {Luo, Zifei and Yang, Wenzhu and Yuan, Yunfeng and Gou, Ruru and Li, Xiaonan},
  year = {2024},
  month = jun,
  journal = {Information Processing in Agriculture},
  volume = {11},
  number = {2},
  pages = {172--186},
  issn = {22143173},
  doi = {10.1016/j.inpa.2023.02.001},
  urldate = {2025-06-09},
  abstract = {As an important research topic in recent years, semantic segmentation has been widely applied to image understanding problems in various fields. With the successful application of deep learning methods in machine vision, the superior performance has been transferred to agricultural image processing by combining them with traditional methods. Semantic segmentation methods have revolutionized the development of agricultural automation and are commonly used for crop cover and type analysis, pest and disease identification, etc. We first give a review of the recent advances in traditional and deep learning methods for semantic segmentation of agricultural images according to different segmentation principles. Then we introduce the traditional methods that can effectively utilize the original image information and the powerful performance of deep learningbased methods. Finally, we outline their applications in agricultural image segmentation. In our literature, we identify the challenges in agricultural image segmentation and summarize the innovative developments that address these challenges. The robustness of the existing segmentation methods for processing complex images still needs to be improved urgently, and their generalization abilities are also insufficient. In particular, the limited number of labeled samples is a roadblock to new developed deep learning methods for their training and evaluation. To this, segmentation methods that augment the dataset or incorporate multimodal information enable deep learning methods to further improve the segmentation capabilities. This review provides a reference for the application of image semantic segmentation in the field of agricultural informatization.},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/YIKBFJG4/Luo et al. - 2024 - Semantic segmentation of agricultural images A survey.pdf}
}
@article{kussulDeepLearningClassification2017,
  title = {Deep {{Learning Classification}} of {{Land Cover}} and {{Crop Types Using Remote Sensing Data}}},
  author = {Kussul, Nataliia and Lavreniuk, Mykola and Skakun, Sergii and Shelestov, Andrii},
  year = {2017},
  month = may,
  journal = {IEEE Geoscience and Remote Sensing Letters},
  volume = {14},
  number = {5},
  pages = {778--782},
  issn = {1545-598X, 1558-0571},
  doi = {10.1109/LGRS.2017.2681128},
  urldate = {2025-06-13},
  abstract = {Deep learning (DL) is a powerful state-of-the-art technique for image processing including remote sensing (RS) images. This letter describes a multilevel DL architecture that targets land cover and crop type classification from multitemporal multisource satellite imagery. The pillars of the architecture are unsupervised neural network (NN) that is used for optical imagery segmentation and missing data restoration due to clouds and shadows, and an ensemble of supervised NNs. As basic supervised NN architecture, we use a traditional fully connected multilayer perceptron (MLP) and the most commonly used approach in RS community random forest, and compare them with convolutional NNs (CNNs). Experiments are carried out for the joint experiment of crop assessment and monitoring test site in Ukraine for classification of crops in a heterogeneous environment using nineteen multitemporal scenes acquired by Landsat-8 and Sentinel-1A RS satellites. The architecture with an ensemble of CNNs outperforms the one with MLPs allowing us to better discriminate certain summer crop types, in particular maize and soybeans, and yielding the target accuracies more than 85\% for all major crops (wheat, maize, sunflower, soybeans, and sugar beet).},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/A4K3UAZP/Kussul et al. - 2017 - Deep Learning Classification of Land Cover and Crop Types Using Remote Sensing Data.pdf}
}
@misc{ronnebergerUNetConvolutionalNetworks2015,
  title = {U-{{Net}}: {{Convolutional Networks}} for {{Biomedical Image Segmentation}}},
  shorttitle = {U-{{Net}}},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  year = {2015},
  month = may,
  number = {arXiv:1505.04597},
  eprint = {1505.04597},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1505.04597},
  urldate = {2025-06-13},
  abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/maysu-wk/Zotero/storage/HPMP25SX/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image Segmentation.pdf;/home/maysu-wk/Zotero/storage/CYM5PDIM/1505.html}
}
@article{chenDeepLabSemanticImage2018,
  title = {{{DeepLab}}: {{Semantic Image Segmentation}} with {{Deep Convolutional Nets}}, {{Atrous Convolution}}, and {{Fully Connected CRFs}}},
  shorttitle = {{{DeepLab}}},
  author = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
  year = {2018},
  month = apr,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {40},
  number = {4},
  pages = {834--848},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2017.2699184},
  urldate = {2025-06-13},
  abstract = {In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled filters, or `atrous convolution', as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with filters at multiple sampling rates and effective fields-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed ``DeepLab'' system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7 percent mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.},
  keywords = {atrous convolution,Computational modeling,conditional random fields,Context,Convolution,Convolutional neural networks,Image resolution,Image segmentation,Neural networks,semantic segmentation,Semantics},
  file = {/home/maysu-wk/Zotero/storage/8A5RWGMW/Chen et al. - 2018 - DeepLab Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Con.pdf}
}
@misc{chenRethinkingAtrousConvolution2017,
  title = {Rethinking {{Atrous Convolution}} for {{Semantic Image Segmentation}}},
  author = {Chen, Liang-Chieh and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  year = {2017},
  month = dec,
  number = {arXiv:1706.05587},
  eprint = {1706.05587},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1706.05587},
  urldate = {2025-06-13},
  abstract = {In this work, we revisit atrous convolution, a powerful tool to explicitly adjust filter's field-of-view as well as control the resolution of feature responses computed by Deep Convolutional Neural Networks, in the application of semantic image segmentation. To handle the problem of segmenting objects at multiple scales, we design modules which employ atrous convolution in cascade or in parallel to capture multi-scale context by adopting multiple atrous rates. Furthermore, we propose to augment our previously proposed Atrous Spatial Pyramid Pooling module, which probes convolutional features at multiple scales, with image-level features encoding global context and further boost performance. We also elaborate on implementation details and share our experience on training our system. The proposed `DeepLabv3' system significantly improves over our previous DeepLab versions without DenseCRF post-processing and attains comparable performance with other state-of-art models on the PASCAL VOC 2012 semantic image segmentation benchmark.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/maysu-wk/Zotero/storage/AEZJGE4Q/Chen et al. - 2017 - Rethinking Atrous Convolution for Semantic Image Segmentation.pdf;/home/maysu-wk/Zotero/storage/SPI8YUTC/1706.html}
}
@inproceedings{chenEncoderDecoderAtrousSeparable2018,
  title = {Encoder-{{Decoder}} with {{Atrous Separable Convolution}} for {{Semantic Image Segmentation}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2018},
  author = {Chen, Liang-Chieh and Zhu, Yukun and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  year = {2018},
  pages = {833--851},
  publisher = {Springer, Cham},
  issn = {1611-3349},
  doi = {10.1007/978-3-030-01234-2_49},
  urldate = {2025-06-13},
  abstract = {Spatial pyramid pooling module or encode-decoder structure are used in deep neural networks for semantic segmentation task. The former networks are able to encode multi-scale contextual information by probing the incoming features with filters or pooling operations...},
  isbn = {978-3-030-01234-2},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/GPH8Z96J/Chen et al. - 2018 - Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation.pdf}
}
@article{saraivaAutomaticMappingCenter2020,
  title = {Automatic {{Mapping}} of {{Center Pivot Irrigation Systems}} from {{Satellite Images Using Deep Learning}}},
  author = {Saraiva, Marciano and Protas, {\'E}glen and Salgado, Mois{\'e}s and Souza, Carlos},
  year = {2020},
  month = jan,
  journal = {Remote Sensing},
  volume = {12},
  number = {3},
  pages = {558},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs12030558},
  urldate = {2025-06-13},
  abstract = {The availability of freshwater is becoming a global concern. Because agricultural consumption has been increasing steadily, the mapping of irrigated areas is key for supporting the monitoring of land use and better management of available water resources. In this paper, we propose a method to automatically detect and map center pivot irrigation systems using U-Net, an image segmentation convolutional neural network architecture, applied to a constellation of PlanetScope images from the Cerrado biome of Brazil. Our objective is to provide a fast and accurate alternative to map center pivot irrigation systems with very high spatial and temporal resolution imagery. We implemented a modified U-Net architecture using the TensorFlow library and trained it on the Google cloud platform with a dataset built from more than 42,000 very high spatial resolution PlanetScope images acquired between August 2017 and November 2018. The U-Net implementation achieved a precision of 99\% and a recall of 88\% to detect and map center pivot irrigation systems in our study area. This method, proposed to detect and map center pivot irrigation systems, has the potential to be scaled to larger areas and improve the monitoring of freshwater use by agricultural activities.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {artificial intelligence,neural networks,semantic segmentation,water management},
  file = {/home/maysu-wk/Zotero/storage/MD9H7EPN/Saraiva et al. - 2020 - Automatic Mapping of Center Pivot Irrigation Systems from Satellite Images Using Deep Learning.pdf}
}
@article{debemChangeDetectionDeforestation2020,
  title = {Change {{Detection}} of {{Deforestation}} in the {{Brazilian Amazon Using Landsat Data}} and {{Convolutional Neural Networks}}},
  author = {{de Bem}, Pablo Pozzobon and {de Carvalho Junior}, Osmar Ab{\'i}lio and Fontes Guimar{\~a}es, Renato and Trancoso Gomes, Roberto Arnaldo},
  year = {2020},
  month = jan,
  journal = {Remote Sensing},
  volume = {12},
  number = {6},
  pages = {901},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-4292},
  doi = {10.3390/rs12060901},
  urldate = {2025-06-13},
  abstract = {Mapping deforestation is an essential step in the process of managing tropical rainforests. It lets us understand and monitor both legal and illegal deforestation and its implications, which include the effect deforestation may have on climate change through greenhouse gas emissions. Given that there is ample room for improvements when it comes to mapping deforestation using satellite imagery, in this study, we aimed to test and evaluate the use of algorithms belonging to the growing field of deep learning (DL), particularly convolutional neural networks (CNNs), to this end. Although studies have been using DL algorithms for a variety of remote sensing tasks for the past few years, they are still relatively unexplored for deforestation mapping. We attempted to map the deforestation between images approximately one year apart, specifically between 2017 and 2018 and between 2018 and 2019. Three CNN architectures that are available in the literature---SharpMask, U-Net, and ResUnet---were used to classify the change between years and were then compared to two classic machine learning (ML) algorithms---random forest (RF) and multilayer perceptron (MLP)---as points of reference. After validation, we found that the DL models were better in most performance metrics including the Kappa index, F1 score, and mean intersection over union (mIoU) measure, while the ResUnet model achieved the best overall results with a value of 0.94 in all three measures in both time sequences. Visually, the DL models also provided classifications with better defined deforestation patches and did not need any sort of post-processing to remove noise, unlike the ML models, which needed some noise removal to improve results.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {change detection,classification,CNN,deep learning,deforestation},
  file = {/home/maysu-wk/Zotero/storage/23SN7D8Y/de Bem et al. - 2020 - Change Detection of Deforestation in the Brazilian Amazon Using Landsat Data and Convolutional Neura.pdf}
}
@article{bemIrrigatedRiceCrop2021,
  title = {Irrigated Rice Crop Identification in {{Southern Brazil}} Using Convolutional Neural Networks and {{Sentinel-1}} Time Series},
  author = {Bem, Pablo Pozzobon De and De Carvalho J{\'u}nior, Osmar Ab{\'i}lio and Carvalho, Osmar Luiz Ferreira De and Gomes, Roberto Arnaldo Trancoso and Guimar{\=a}es, Renato Fontes and Pimentel, Concepta Margaret McManus},
  year = {2021},
  month = nov,
  journal = {Remote Sensing Applications: Society and Environment},
  volume = {24},
  pages = {100627},
  issn = {23529385},
  doi = {10.1016/j.rsase.2021.100627},
  urldate = {2025-06-13},
  abstract = {Rice is one of the world's staple food sources, with millions of tonnes produced and consumed every year. Therefore, mapping rice paddies is essential for agricultural management and ensuring food security. This study aimed to classify rice crops in southern Brazil using the SENTINEL-1 SAR time series and deep learning models, comparing two architectures (U-net and LinkNet) and four backbones (ResNet-34, ResNeXt-50, DenseNet-121, and VGG16). The time series construction considered ten images, each for a month, covering the rice planting cycle. The Convolutional Neural Network architectures were adapted to use multi-band data, allowing the extraction of features from all-temporal images. This approach provides capturing spatiotemporal information from rice plantations, which favors its detection. Besides, the research evaluated three data sets considering the polarizations: (a) VV-only, (b) VH-only, and (c) both VV and VH (VV + VH). The classification accuracies used to measure the performance of the models were the overall accuracy, F1-measure, area under the precision-recall curve (AUPRC), and the intersection over union (IoU). Results show that the VH + VV polarization combination yielded the best results, followed by VH-only and VV-only. The VV-only polarization had significantly worst results (nearly 10\% less IoU than VH-only and nearly 15\% less IoU compared to VV + VH). The results show that rice fields can be successfully classified with deep learning models and through our evaluation the LinkNet architecture with the ResNeXt-50 backbone showed the best results with an accuracy of 0.98, F1 of 0.93, AUPRC of 0.93, and IoU of 0.91.},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/Q9XGENQW/Bem et al. - 2021 - Irrigated rice crop identification in Southern Brazil using convolutional neural networks and Sentin.pdf}
}
@article{zhuDeepLearningRemote2017,
  title = {Deep {{Learning}} in {{Remote Sensing}}: {{A Comprehensive Review}} and {{List}} of {{Resources}}},
  shorttitle = {Deep {{Learning}} in {{Remote Sensing}}},
  author = {Zhu, Xiao Xiang and Tuia, Devis and Mou, Lichao and Xia, Gui-Song and Zhang, Liangpei and Xu, Feng and Fraundorfer, Friedrich},
  year = {2017},
  month = dec,
  journal = {IEEE Geoscience and Remote Sensing Magazine},
  volume = {5},
  number = {4},
  pages = {8--36},
  issn = {2168-6831},
  doi = {10.1109/MGRS.2017.2762307},
  urldate = {2025-06-13},
  abstract = {Central to the looming paradigm shift toward data-intensive science, machine-learning techniques are becoming increasingly important. In particular, deep learning has proven to be both a major breakthrough and an extremely powerful tool in many fields. Shall we embrace deep learning as the key to everything? Or should we resist a black-box solution? These are controversial issues within the remote-sensing community. In this article, we analyze the challenges of using deep learning for remote-sensing data analysis, review recent advances, and provide resources we hope will make deep learning in remote sensing seem ridiculously simple. More importantly, we encourage remote-sensing scientists to bring their expertise into deep learning and use it as an implicit general model to tackle unprecedented, large-scale, influential challenges, such as climate change and urbanization.},
  keywords = {Climate change,Computer vision,Feature extraction,Hyperspectral imaging,Machine learning,Remote sensing,Tutorials},
  file = {/home/maysu-wk/Zotero/storage/DB8PLWEW/Zhu et al. - 2017 - Deep Learning in Remote Sensing A Comprehensive Review and List of Resources.pdf}
}
@article{liCascadeDeepLabNet2025,
  title = {Cascade {{DeepLab Net}}: {{A Method}} for {{Accurate Extraction}} of {{Fragmented Cultivated Land}} in {{Mountainous Areas Based}} on a {{Cascaded Network}}},
  shorttitle = {Cascade {{DeepLab Net}}},
  author = {Li, Man and Wang, Renru and Dai, Ana and Yuan, Weitao and Yang, Guangbin and Xie, Lijun and Zhao, Weili and Zhao, Linglin},
  year={2025},
  date = {2025-02-06},
  journal = {Agriculture},
  shortjournal = {Agriculture},
  volume = {15},
  number = {3},
  pages = {348},
  issn = {2077-0472},
  doi = {10.3390/agriculture15030348},
  url = {https://www.mdpi.com/2077-0472/15/3/348},
  urldate = {2025-06-13},
  abstract = {Approximately 24\% of the global land area consists of mountainous regions, with 10\% of the population relying on these areas for their cultivated land. Accurate statistics and monitoring of cultivated land in mountainous regions are crucial for ensuring food security, creating scientific land use policies, and protecting the ecological environment. However, the fragmented nature of cultivated land in these complex terrains challenges the effectiveness of existing extraction methods. To address this issue, this study proposed a cascaded network based on an improved semantic segmentation model (DeepLabV3+), called Cascade DeepLab Net, specifically designed to improve the accuracy in the scenario of fragmented land features. This method aims to accurately extract cultivated land from remote sensing images. This model enhances the accuracy of cultivated land extraction in complex terrains by incorporating the Style-based Recalibration Module (SRM), Spatial Attention Module (SAM), and Refinement Module (RM). The experimental results using high-resolution satellite images of mountainous areas in southern China show that the improved model achieved an overall accuracy (OA) of 92.33\% and an Intersection over Union (IoU) of 82.51\%, marking a significant improvement over models such as U-shaped Network (UNet), Pyramid Scene Parsing Network (PSPNet), and DeepLabV3+. This method enhances the efficiency and accuracy of monitoring cultivated land in mountainous areas and offers a scientific basis for policy formulation and resource management, aiding in ecological protection and sustainable development. Additionally, this study presents new ideas and methods for future applications of cultivated land monitoring in other complex terrain regions.},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/DIJJSY3K/Li et al. - 2025 - Cascade DeepLab Net A Method for Accurate Extraction of Fragmented Cultivated Land in Mountainous A.pdf}
}
@article{zhang2023cultivated,
  title = {Progress and Prospect of Cultivated Land Extraction from High-Resolution Remote Sensing Images},
  author = {Zhang, Xinchang and Huang, Jianfeng and Ning, Ting},
  year = {2023},
  journal = {Geomatics and Information Science of Wuhan University},
  volume = {48},
  number = {10},
  pages = {1582--1590},
  doi = {10.13203/j.whugis20230114},
  file = {/home/maysu-wk/Zotero/storage/UV6B5XQE/Zhang et al. - 2023 - Progress and prospect of cultivated land extraction from high-resolution remote sensing images.pdf}
}
@article{moherPreferredReportingItems2009,
  title = {Preferred Reporting Items for Systematic Reviews and Meta-Analyses: The {{PRISMA}} Statement},
  shorttitle = {Preferred Reporting Items for Systematic Reviews and Meta-Analyses},
  author = {Moher, D. and Liberati, A. and Tetzlaff, J. and Altman, D. G and {for the PRISMA Group}},
  year = {2009},
  month = jul,
  journal = {BMJ},
  volume = {339},
  number = {jul21 1},
  pages = {b2535-b2535},
  issn = {0959-8138, 1468-5833},
  doi = {10.1136/bmj.b2535},
  urldate = {2025-06-13},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/NPZGDXU6/Moher et al. - 2009 - Preferred reporting items for systematic reviews and meta-analyses the PRISMA statement.pdf}
}
@misc{parsifal,
  author       = {Brereton, P. and Kitchenham, B. and Budgen, D.},
  title        = {Parsifal: A Web-based Tool for Systematic Review Protocols},
  howpublished = {\url{https://parsif.al}},
  note         = {Acesso em: junho de 2025}
}
@manual{python,
  title        = {Python Language Reference, version 3.10},
  author       = {{Python Software Foundation}},
  year         = {2021},
  note         = {\url{https://www.python.org}}
}
@manual{rsoftware,
  title        = {R: A Language and Environment for Statistical Computing},
  author       = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address      = {Vienna, Austria},
  year         = {2023},
  url          = {https://www.R-project.org/}
}
@article{metafor,
  title   = {Conducting Meta-Analyses in R with the metafor Package},
  author  = {Wolfgang Viechtbauer},
  journal = {Journal of Statistical Software},
  year    = {2010},
  volume  = {36},
  number  = {3},
  pages   = {1--48},
  doi     = {10.18637/jss.v036.i03}
}
@article{ayushiSatelliteImageryAnalysis2024,
  title = {Satellite {{Imagery Analysis}} for {{Crop Type Segmentation Using U-Net Architecture}}},
  author = {{Ayushi} and Buttar, Preetpal Kaur},
  year = {2024},
  journal = {Procedia Computer Science},
  volume = {235},
  pages = {3418--3427},
  issn = {18770509},
  doi = {10.1016/j.procs.2024.04.322},
  urldate = {2025-06-09},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/F3F8Z25A/Ayushi e Buttar - 2024 - Satellite Imagery Analysis for Crop Type Segmentation Using U-Net Architecture.pdf}
}

@article{dealbuquerqueDeepSemanticSegmentation2020,
  title = {Deep {{Semantic Segmentation}} of {{Center Pivot Irrigation Systems}} from {{Remotely Sensed Data}}},
  author = {De Albuquerque, Anesmar Olino and De Carvalho J{\'u}nior, Osmar Ab{\'i}lio and Carvalho, Osmar Luiz Ferreira De and De Bem, Pablo Pozzobon and Ferreira, Pedro Henrique Guimar{\~a}es and De Moura, Rebeca Dos Santos and Silva, Cristiano Rosa and Trancoso Gomes, Roberto Arnaldo and Fontes Guimar{\~a}es, Renato},
  year = {2020},
  month = jul,
  journal = {Remote Sensing},
  volume = {12},
  number = {13},
  pages = {2159},
  issn = {2072-4292},
  doi = {10.3390/rs12132159},
  urldate = {2025-06-13},
  abstract = {The center pivot irrigation system (CPIS) is a modern irrigation technique widely used in precision agriculture due to its high efficiency in water consumption and low labor compared to traditional irrigation methods. The CPIS is a leader in mechanized irrigation in Brazil, with growth forecast for the coming years. Therefore, the mapping of center pivot areas is a strategic factor for the estimation of agricultural production, ensuring food security, water resources management, and environmental conservation. In this regard, digital processing of satellite images is the primary tool allowing regional and continuous monitoring with low costs and agility. However, the automatic detection of CPIS using remote sensing images remains a challenge, and much research has adopted visual interpretation. Although CPIS presents a consistent circular shape in the landscape, these areas can have a high internal variation with different plantations that vary over time, which is difficult with just the spectral behavior. Deep learning using convolutional neural networks (CNNs) is an emerging approach that provokes a revolution in image segmentation, surpassing traditional methods, and achieving higher accuracy and efficiency. This research aimed to evaluate the use of deep semantic segmentation of CPIS from CNN-based algorithms using Landsat-8 surface reflectance images (seven bands). The developed methodology can be subdivided into the following steps: (a) Definition of three study areas with a high concentration of CPIS in Central Brazil; (b) acquisition of Landsat-8 images considering the seasonal variations of the rain and drought periods; (c) definition of CPIS datasets containing Landsat images and ground truth mask of 256{\texttimes}256 pixels; (d) training using three CNN architectures (U-net, Deep ResUnet, and SharpMask); (e) accuracy analysis; and (f) large image reconstruction using six stride values (8, 16, 32, 64, 128, and 256). The three methods achieved state-of-the-art results with a slight prevalence of U-net over Deep ResUnet and SharpMask (0.96, 0.95, and 0.92 Kappa coefficients, respectively). A novelty in this research was the overlapping pixel analysis in the large image reconstruction. Lower stride values had improvements quantified by the Receiver Operating Characteristic curve (ROC curve) and Kappa, and fewer errors in the frame edges were also perceptible. The overlapping images significantly improved the accuracy and reduced the error present in the edges of the classified frames. Additionally, we obtained greater accuracy results during the beginning of the dry season. The present study enabled the establishment of a database of center pivot images and an adequate methodology for mapping the center pivot in central Brazil.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/VJLIRNE3/De Albuquerque et al. - 2020 - Deep Semantic Segmentation of Center Pivot Irrigation Systems from Remotely Sensed Data.pdf}
}

@inproceedings{gargiuloSemanticSegmentationUsing2019,
  title = {Semantic {{Segmentation}} Using {{Deep Learning}}: {{A}} Case of Study in {{Albufera Park}}, {{Valencia}}},
  shorttitle = {Semantic {{Segmentation}} Using {{Deep Learning}}},
  booktitle = {2019 {{IEEE International Workshop}} on {{Metrology}} for {{Agriculture}} and {{Forestry}} ({{MetroAgriFor}})},
  author = {Gargiulo, Massimiliano and Dell'Aglio, Domenico A. G. and Iodice, Antonio and Riccio, Daniele and Ruello, Giuseppe},
  year = {2019},
  month = oct,
  pages = {134--138},
  publisher = {IEEE},
  address = {Portici, Italy},
  doi = {10.1109/MetroAgriFor.2019.8909243},
  urldate = {2025-06-13},
  abstract = {In this work, we explore the potential of using Sentinel-1 (S1) dual-polarization Synthetic Aperture Radar (SAR) data to obtain semantic maps that may complement those provided by the Level-2A (L2A) product of Sentinel-2 (S2). Specifically, we consider the use of the Interferometric Wide swath mode (IW) Sentinel-1 (S1) data collected along ascending/descending orbit, for wetlands and rice growing monitoring over the Natural Park of Albufera, Valencia. For this purpose, supervised Deep Learning (DL) approaches have been proposed to classify the pixels of the interested area. The advantages and disadvantages of different input stacks have been analysed, and the results have been assessed in terms of Accuracy, F1-score, Precision, and Recall. The results demonstrate that dual polarimetric Sentinel-1 SAR data can be effectively integrated in land cover maps produced by Sentinel2 multispectral data. This approach is particularly helpful for rapid vegetation dynamics in tropical weather countries.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  isbn = {978-1-7281-3611-0},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/DCXZNIKP/Gargiulo et al. - 2019 - Semantic Segmentation using Deep Learning A case of study in Albufera Park, Valencia.pdf}
}

@article{grafSemanticSegmentationSentinel22020,
  title = {Semantic {{Segmentation}} of {{Sentinel-2 Imagery}} for {{Mapping Irrigation Center Pivots}}},
  author = {Graf, Lukas and Bach, Heike and Tiede, Dirk},
  year = {2020},
  month = dec,
  journal = {Remote Sensing},
  volume = {12},
  number = {23},
  pages = {3937},
  issn = {2072-4292},
  doi = {10.3390/rs12233937},
  urldate = {2025-06-13},
  abstract = {Estimating the number and size of irrigation center pivot systems (CPS) from remotely sensed data, using artificial intelligence (AI), is a potential information source for assessing agricultural water use. In this study, we identified two technical challenges in the neural-network-based classification: Firstly, an effective reduction of the feature space of the remote sensing data to shorten training times and increase classification accuracy is required. Secondly, the geographical transferability of the AI algorithms is a pressing issue if AI is to replace human mapping efforts one day. Therefore, we trained the semantic image segmentation algorithm U-NET on four spectral channels (U-NET SPECS) and the first three principal components (U-NET principal component analysis (PCA)) of ESA/Copernicus Sentinel-2 images on a study area in Texas, USA, and assessed the geographic transferability of the trained models to two other sites: the Duero basin, in Spain, and South Africa. U-NET SPECS outperformed U-NET PCA at all three study areas, with the highest f1-score at Texas (0.87, U-NET PCA: 0.83), and a value of 0.68 (U-NET PCA: 0.43) in South Africa. At the Duero, both models showed poor classification accuracy (f1-score U-NET PCA: 0.08; U-NET SPECS: 0.16) and segmentation quality, which was particularly evident in the incomplete representation of the center pivot geometries. In South Africa and at the Duero site, a high rate of false positive and false negative was observed, which made the model less useful, especially at the Duero test site. Thus, geographical invariance is not an inherent model property and seems to be mainly driven by the complexity of land-use pattern. We do not consider PCA a suited spectral dimensionality reduction measure in this. However, shorter training times and a more stable training process indicate promising prospects for reducing computational burdens. We therefore conclude that effective dimensionality reduction and geographic transferability are important prospects for further research towards the operational usage of deep learning algorithms, not only regarding the mapping of CPS.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/2JE6324Z/Graf et al. - 2020 - Semantic Segmentation of Sentinel-2 Imagery for Mapping Irrigation Center Pivots.pdf}
}

@article{luExtractionAgriculturalFields2022,
  title = {Extraction of {{Agricultural Fields}} via {{DASFNet}} with {{Dual Attention Mechanism}} and {{Multi-scale Feature Fusion}} in {{South Xinjiang}}, {{China}}},
  author = {Lu, Rui and Wang, Nan and Zhang, Yanbin and Lin, Yeneng and Wu, Wenqiang and Shi, Zhou},
  year = {2022},
  month = may,
  journal = {Remote Sensing},
  volume = {14},
  number = {9},
  pages = {2253},
  issn = {2072-4292},
  doi = {10.3390/rs14092253},
  urldate = {2025-06-13},
  abstract = {Agricultural fields are essential in providing human beings with paramount food and other materials. Quick and accurate identification of agricultural fields from the remote sensing images is a crucial task in digital and precision agriculture. Deep learning methods have the advantages of fast and accurate image segmentation, especially for extracting the agricultural fields from remote sensing images. This paper proposed a deep neural network with a dual attention mechanism and a multi-scale feature fusion (Dual Attention and Scale Fusion Network, DASFNet) to extract the cropland from a GaoFen-2 (GF-2) image of 2017 in Alar, south Xinjiang, China. First, we constructed an agricultural field segmentation dataset from the GF-2 image. Next, seven evaluation indices were selected to assess the extraction accuracy, including the location shift, to reveal the spatial relationship and facilitate a better evaluation. Finally, we proposed DASFNet incorporating three ameliorated and novel deep learning modules with the dual attention mechanism and multi-scale feature fusion methods. The comparison of these modules indicated their effects and advantages. Compared with different segmentation convolutional neural networks, DASFNet achieved the best testing accuracy in extracting fields with an F1-score of 0.9017, an intersection over a union of 0.8932, a Kappa coefficient of 0.8869, and a location shift of 1.1752 pixels. Agricultural fields can be extracted automatedly and accurately using DASFNet, which reduces the manual record of the agricultural field information and is conducive to further farmland surveys, protection, and management.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/BK343YF3/Lu et al. - 2022 - Extraction of Agricultural Fields via DASFNet with Dual Attention Mechanism and Multi-scale Feature.pdf}
}

@article{raufNewMethodPixel2022,
  title = {A New Method for Pixel Classification for Rice Variety Identification Using Spectral and Time Series Data from {{Sentinel-2}} Satellite Imagery},
  author = {Rauf, Usman and Qureshi, Waqar S. and Jabbar, Hamid and Zeb, Ayesha and Mirza, Alina and Alanazi, Eisa and Khan, Umar S. and Rashid, Nasir},
  year = {2022},
  month = feb,
  journal = {Computers and Electronics in Agriculture},
  volume = {193},
  pages = {106731},
  issn = {01681699},
  doi = {10.1016/j.compag.2022.106731},
  urldate = {2025-06-13},
  abstract = {In the agriculture sector food productivity, security, and sustainability, imposed challenges on farmers, regulatory bodies, and policymakers due to increasing demand and depleting natural resources and environmental concerns. Rice crop holds a prominent place in Pakistan's agriculture sector, it is not only consumed locally but also exported to many countries including China. Gathering crop information such as variety maps, yield estimation, or etc. can help farmers, regulatory bodies, policymakers, and rice mills in decision-making. In Pakistan, crop information is collected through manual field surveys that require a lot of human labor, are costly, and are time-consuming. One cannot ignore human error and bias in the process. A new framework for pixel classification is proposed that uses both spectral and time-series data of Sentinal-2 satellite for mapping two rice varieties ``Basmati'' and ``IRRI, grown in Pakistan. The data were collected from twelve rice fields (approx. 307 acres) of different geographical locations at 16-time instances to cover the complete rice-growing season (May--October) in 2019. A linear spectral unmixing model is used to determine sub-pixel information of water, soil, and vegetation content, which is used for labeling each pixel for supervised learning. The input to our classifier is a 16 {\texttimes} 15 image formed using 15 spectral features (12 spectral bands and 3 radiometric indices) of 16 carefully selected different time instances for each pixel. The output is a pixel-level classification (semantic segmentation) of each pixel into Basmati, IRRI, and others (soil, water, etc.). Experimental results have exhibited an excellent overall accuracy of 98.6\% with the proposed approach. The Basmati rice obtained higher accuracy of 99.7\% as compared to IRRI rice with an accuracy of 95.2\%.},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/YLGV99YN/Rauf et al. - 2022 - A new method for pixel classification for rice variety identification using spectral and time series.pdf}
}

@article{sunAccurateMappingRapeseed2024,
  title = {Accurate Mapping of Rapeseed Fields in the Initial Flowering Stage Using {{Sentinel-2}} Satellite Images and Convolutional Neural Networks},
  author = {Sun, Yifei and Hao, Zhenbang and Chang, Hongcai and Yang, Jialin and Ding, Guiling and Guo, Zhanbao and He, Xi and Huang, Jiaxing},
  year = {2024},
  month = may,
  journal = {Ecological Indicators},
  volume = {162},
  pages = {112027},
  issn = {1470160X},
  doi = {10.1016/j.ecolind.2024.112027},
  urldate = {2025-06-13},
  abstract = {In high-intensity farming, swiftly and accurately adjusting the proportion of artificially reared pollinators according to the flowering phenology of crops is vital. This adjustment is essential for sustaining crop yields without disrupting the ecological niche of native pollinators. Although advancements in remote sensing provide practical means to gather data on crop coverage and extent, identifying insect-pollinated crops during their initial flowering to guide the deployment of managed pollinators is an underexamined research area. Here, we tested the capability of utilizing Sentinel-2 satellite images combined with a deep learning model to map crop fields during the initial flowering stage of insect-pollinated crops in Zhaosu County, Xinjiang, China. Specifically, we examined rapeseed fields by employing 12 neural network designs to identify images of the initial flowering stage. Different network combinations of three convolutional neural network (CNN) models (U-Net, PSPNet, and DeepLab V3) and four different backbone networks (ResNet-18, ResNet-34, ResNet-50, and ResNet-101) were explored to determine the most effective model for detecting rapeseed fields at the initial flowering stage. A comparison was conducted with Sentinel-2 images obtained at the peak stage of rapeseed flowering. Our results suggest that the use of a deep learning model in combination with Sentinel-2 image data can successfully identify rapeseed fields at the initial flowering stage, thereby offering preliminary insights for the strategic introduction of managed pollinators. The PSPNet model emerged as the superior choice for the identification of rapeseed fields, exhibiting high accuracy in both detection and boundary recognition, with F1 scores of 88.17 \% and an intersection over union (IoU) of 53.11 \% during initial flowering and F1 scores of 93.33 \% with an IoU of 53.49 \% during peak flowering. The planting area of rapeseed fields detected by the model in Zhaosu County was 122.16 km2, distributed within an area of 1068 km2. These findings can provide foundational data for informed decisions regarding artificial pollinator supplementation, helping to sustain the health and stability of agricultural ecosystems.},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/Q756YTX3/Sun et al. - 2024 - Accurate mapping of rapeseed fields in the initial flowering stage using Sentinel-2 satellite images.pdf}
}

@inproceedings{xueMultiscaleResidualSpatialSpectral2023,
  title = {Multi-Scale {{Residual Spatial-Spectral Attention Longan-Litchi Extraction Network}} for {{Cultivated Land Non-grain Monitoring}}},
  booktitle = {2023 11th {{International Conference}} on {{Agro-Geoinformatics}} ({{Agro-Geoinformatics}})},
  author = {Xue, Yingshan and Jiang, Yonghua and Wang, Chengjun and Wu, Kaiwen and Zhang, Xiaoxiao and Liu, Weiling},
  year = {2023},
  month = jul,
  pages = {1--5},
  publisher = {IEEE},
  address = {Wuhan, China},
  doi = {10.1109/Agro-Geoinformatics59224.2023.10233306},
  urldate = {2025-06-13},
  abstract = {With the continuous development of remote sensing earth observation technology, the acquisition of remote sensing data has become more convenient, and it has been widely used in fields such as agricultural resource investigation, disaster monitoring, and agricultural information management. Hyperspectral imagery has the characteristics of "unity of maps and spectra", wide wavelength range, large number of bands, complete spectral curves and rich information, which can provide more detailed spectral information for earth observation. It is also of great significance to the development of precision agriculture.},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {979-8-3503-0351-3},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/L529MCZ6/[12] Multi-scale_Residual_Spatial-Spectral_Attention_Longan-Litchi_Extraction_Network_for_Cultivated_Land_Non-grain_Monitoring.pdf}
}

@article{xuHighResolutionUNetPreserving2020,
  title = {High-{{Resolution U-Net}}: {{Preserving Image Details}} for {{Cultivated Land Extraction}}},
  shorttitle = {High-{{Resolution U-Net}}},
  author = {Xu, Wenna and Deng, Xinping and Guo, Shanxin and Chen, Jinsong and Sun, Luyi and Zheng, Xiaorou and Xiong, Yingfei and Shen, Yuan and Wang, Xiaoqin},
  year = {2020},
  month = jul,
  journal = {Sensors},
  volume = {20},
  number = {15},
  pages = {4064},
  issn = {1424-8220},
  doi = {10.3390/s20154064},
  urldate = {2025-06-13},
  abstract = {Accurate and efficient extraction of cultivated land data is of great significance for agricultural resource monitoring and national food security. Deep-learning-based classification of remote-sensing images overcomes the two difficulties of traditional learning methods (e.g., support vector machine (SVM), K-nearest neighbors (KNN), and random forest (RF)) when extracting the cultivated land: (1) the limited performance when extracting the same land-cover type with the high intra-class spectral variation, such as cultivated land with both vegetation and non-vegetation cover, and (2) the limited generalization ability for handling a large dataset to apply the model to different locations. However, the ``pooling'' process in most deep convolutional networks, which attempts to enlarge the sensing field of the kernel by involving the upscale process, leads to significant detail loss in the output, including the edges, gradients, and image texture details. To solve this problem, in this study we proposed a new end-to-end extraction algorithm, a high-resolution U-Net (HRU-Net), to preserve the image details by improving the skip connection structure and the loss function of the original U-Net. The proposed HRU-Net was tested in Xinjiang Province, China to extract the cultivated land from Landsat Thematic Mapper (TM) images. The result showed that the HRU-Net achieved better performance (Acc: 92.81\%; kappa: 0.81; F1-score: 0.90) than the U-Net++ (Acc: 91.74\%; kappa: 0.79; F1-score: 0.89), the original U-Net (Acc: 89.83\%; kappa: 0.74; F1-score: 0.86), and the Random Forest model (Acc: 76.13\%; kappa: 0.48; F1-score: 0.69). The robustness of the proposed model for the intra-class spectral variation and the accuracy of the edge details were also compared, and this showed that the HRU-Net obtained more accurate edge details and had less influence from the intra-class spectral variation. The model proposed in this study can be further applied to other land cover types that have more spectral diversity and require more details of extraction.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/RVXERHEG/Xu et al. - 2020 - High-Resolution U-Net Preserving Image Details for Cultivated Land Extraction.pdf}
}

@article{zhangAgriculturalCultivationParcels2025,
  title = {Toward {{Agricultural Cultivation Parcels Extraction}} in the {{Complex Mountainous Areas Using Prior Information}} and {{Deep Learning}}},
  author = {Zhang, Jing and Wu, Tianjun and Luo, Jiancheng and Hu, Xiaodong and Wang, Lingyu and Li, Manjia and Lu, Xuanzhi and Li, Ziqi},
  year = {2025},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  volume = {63},
  pages = {1--14},
  issn = {0196-2892, 1558-0644},
  doi = {10.1109/TGRS.2025.3530615},
  urldate = {2025-06-13},
  abstract = {Accurately determining the spatial position and distribution structure of agricultural cultivation parcels (ACPs) is essential for regional agricultural planning and food security. Currently, utilizing deep learning technology based on very high resolution remote sensing imagery has proven effective for intelligent parcel extraction. However, relying solely on the model output, especially from single-task models in mountainous regions with complex, heterogeneous, and fragmented smallholder agriculture, remains questionable. To address this challenge, leveraging geographical prior knowledge is critical. This article proposes using the deep semantic segmentation algorithm in conjunction with comprehensive prior strategies. An improved densely connected link network (D-LinkNet) is employed to delineate the parcels, while geographical zoning, coarse spatial scope, stratification strategy, and homogeneity checking are exerted to understand regions, facilitate samples, reduce interferences, decompose objects, and identify undersegmentation. The proposed framework was validated in Jiangjin district, Chongqing of China, using Gaofen-2 images as the vital data. Compared to the method relying solely on deep learning, our method achieved superior performance with an overall accuracy of 0.924, Kappa coefficient of 0.847, F1 score of 0.921, and IoU exceeding 0.8. Moreover, the results demonstrated high accuracy in the individual geometric precision of parcel. Over 1.23 million parcels were identified, comprising 77\% cultivated land and 23\% garden land. The areal proportion of paddy fields, drylands, and pepper gardens approximated 1:1:1, consistent with statistical data. This method offers a feasible approach for finely extracting agricultural parcels.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {/home/maysu-wk/Zotero/storage/RDZBXM99/Zhang et al. - 2025 - Toward Agricultural Cultivation Parcels Extraction in the Complex Mountainous Areas Using Prior Info.pdf}
}
@inproceedings{chaurasiaLinkNetExploitingEncoder2017,
  title = {{{LinkNet}}: {{Exploiting}} Encoder Representations for Efficient Semantic Segmentation},
  shorttitle = {{{LinkNet}}},
  booktitle = {2017 {{IEEE Visual Communications}} and {{Image Processing}} ({{VCIP}})},
  author = {Chaurasia, Abhishek and Culurciello, Eugenio},
  year = {2017},
  month = dec,
  pages = {1--4},
  doi = {10.1109/VCIP.2017.8305148},
  urldate = {2025-06-15},
  abstract = {Pixel-wise semantic segmentation for visual scene understanding not only needs to be accurate, but also efficient in order to find any use in real-time application. Existing algorithms even though are accurate but they do not focus on utilizing the parameters of neural network efficiently. As a result they are huge in terms of parameters and number of operations; hence slow too. In this paper, we propose a novel deep neural network architecture which allows it to learn without any significant increase in number of parameters. Our network uses only 11.5 million parameters and 21.2 GFLOPs for processing an image of resolution 3 {\texttimes} 640 {\texttimes} 360. It gives state-of-the-art performance on CamVid and comparable results on Cityscapes dataset. We also compare our networks processing time on NVIDIA GPU and embedded system device with existing state-of-the-art architectures for different image resolutions.},
  keywords = {Computer architecture,Convolution,Decoding,Image resolution,Real-time systems,Semantics,Training},
  file = {/home/maysu-wk/Zotero/storage/32K3AZJL/Chaurasia e Culurciello - 2017 - LinkNet Exploiting encoder representations for efficient semantic segmentation.pdf}
}
@inproceedings{zhaoPyramidSceneParsing2017,
  title = {Pyramid {{Scene Parsing Network}}},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Zhao, Hengshuang and Shi, Jianping and Qi, Xiaojuan and Wang, Xiaogang and Jia, Jiaya},
  year = {2017},
  month = jul,
  pages = {6230--6239},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2017.660},
  urldate = {2025-06-15},
  abstract = {Scene parsing is challenging for unrestricted open vocabulary and diverse scenes. In this paper, we exploit the capability of global context information by different-region-based context aggregation through our pyramid pooling module together with the proposed pyramid scene parsing network (PSPNet). Our global prior representation is effective to produce good quality results on the scene parsing task, while PSPNet provides a superior framework for pixel-level prediction. The proposed approach achieves state-of-the-art performance on various datasets. It came first in ImageNet scene parsing challenge 2016, PASCAL VOC 2012 benchmark and Cityscapes benchmark. A single PSPNet yields the new record of mIoU accuracy 85.4\% on PASCAL VOC 2012 and accuracy 80.2\% on Cityscapes.},
  keywords = {Automobiles,Convolution,Feature extraction,Image segmentation,Neural networks,Semantics},
  file = {/home/maysu-wk/Zotero/storage/DWCC35M5/Zhao et al. - 2017 - Pyramid Scene Parsing Network.pdf}
}
@book{borenstein2009introduction,
  title={Introduction to Meta-Analysis},
  author={Borenstein, Michael and Hedges, Larry V. and Higgins, Julian P. T. and Rothstein, Hannah R.},
  year={2009},
  publisher={John Wiley \& Sons},
  address={Chichester, UK},
  isbn={978-0-470-05724-7}
}

@book{higgins2022cochrane,
  title={Cochrane Handbook for Systematic Reviews of Interventions},
  author={Higgins, Julian P.T. and Thomas, James and Chandler, Jacqueline and Cumpston, Miranda and Li, Tianjing and Page, Matthew J. and Welch, Vivian A.},
  year={2022},
  publisher={John Wiley \& Sons},
  edition={2nd},
  note={version 6.3}
}

@article{higgins2003measuring,
  title={Measuring inconsistency in meta-analyses},
  author={Higgins, Julian P T and Thompson, Simon G and Deeks, Jonathan J and Altman, Douglas G},
  journal={BMJ},
  volume={327},
  number={7414},
  pages={557--560},
  year={2003},
  publisher={British Medical Journal Publishing Group}
}
@article{panboonyuen2023mevit,
  title = {{{MeViT}}: A Medium-Resolution Vision Transformer for Semantic Segmentation on Landsat Satellite Imagery for Agriculture in Thailand},
  author = {Panboonyuen, Teerapong and Charoenphon, Chaiyut and Satirapod, Chalermchon and {Iam-On}, Nattakarn and Kassanuk, Thitirat},
  year = {2023},
  journal = {Remote Sensing},
  volume = {15},
  number = {21},
  pages = {5124},
  publisher = {MDPI}
}
@book{hosmer2004applied,
  title={Applied Logistic Regression},
  author={Hosmer, D.W. and Lemeshow, S.},
  isbn={9780471654025},
  lccn={00036843},
  series={Applied Logistic Regression},
  url={https://books.google.com.br/books?id=Po0RLQ7USIMC},
  year={2004},
  publisher={Wiley}
}
@book{casella2002statistical,
  title={Statistical Inference},
  author={Casella, G. and Berger, R.L.},
  isbn={9780495391876},
  lccn={2001025794},
  series={Duxbury advanced series},
  url={https://books.google.com.br/books?id=ZpkPPwAACAAJ},
  year={2002},
  publisher={Duxbury Thomson Learning}
}
@article{konstantopoulos2011fixed,
  title={Fixed effects and variance components estimation in three-level meta-analysis},
  author={Konstantopoulos, Spyros},
  journal={Research synthesis methods},
  volume={2},
  number={1},
  pages={61--76},
  year={2011},
  publisher={Wiley Online Library}
}

@book{geronHandsMachineLearning2019,
  title = {Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow},
  author = {Géron, Aurélien},
  year = {2019},
  publisher = {O'Reilly Media},
  edition = {2},
}

@article{sentinel2,
  author    = {Béatrice Hosseini and Bertrand Pflug and Pierre-Louis Franchistéguy and Claire Latry and Léo D'Herbigny},
  title     = {Sentinel-2 mission: Products, algorithms and performances},
  journal   = {Remote Sensing of Environment},
  volume    = {120},
  pages     = {37--57},
  year      = {2012},
  publisher = {Elsevier},
  doi       = {10.1016/j.rse.2011.11.026}
}

@article{WULDER20122,
title = {Opening the archive: How free data has enabled the science and monitoring promise of Landsat},
journal = {Remote Sensing of Environment},
volume = {122},
pages = {2-10},
year = {2012},
note = {Landsat Legacy Special Issue},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2012.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S003442571200034X},
author = {Michael A. Wulder and Jeffrey G. Masek and Warren B. Cohen and Thomas R. Loveland and Curtis E. Woodcock},
keywords = {Landsat, Archive, Science, Policy, Applications, Monitoring, Mapping},
abstract = {Landsat occupies a unique position in the constellation of civilian earth observation satellites, with a long and rich scientific and applications heritage. With nearly 40years of continuous observation – since launch of the first satellite in 1972 – the Landsat program has benefited from insightful technical specification, robust engineering, and the necessary infrastructure for data archive and dissemination. Chiefly, the spatial and spectral resolutions have proven of broad utility and have remained largely stable over the life of the program. The foresighted acquisition and maintenance of a global image archive has proven to be of unmatched value, providing a window into the past and fueling the monitoring and modeling of global land cover and ecological change. In this paper we discuss the evolution of the Landsat program as a global monitoring mission, highlighting in particular the recent change to an open (free) data policy. The new data policy is revolutionizing the use of Landsat data, spurring the creation of robust standard products and new science and applications approaches. Open data access also promotes increased international collaboration to meet the Earth observing needs of the 21st century.}
}