
@article{ WOS:001099544600001,
Author = {Panboonyuen, Teerapong and Charoenphon, Chaiyut and Satirapod,
   Chalermchon},
Title = {MeViT: A Medium-Resolution Vision Transformer for Semantic Segmentation
   on Landsat Satellite Imagery for Agriculture in Thailand},
Journal = {REMOTE SENSING},
Year = {2023},
Volume = {15},
Number = {21},
Month = {NOV},
Abstract = {Semantic segmentation is a fundamental task in remote sensing image
   analysis that aims to classify each pixel in an image into different
   land use and land cover (LULC) segmentation tasks. In this paper, we
   propose MeViT (Medium-Resolution Vision Transformer) on Landsat
   satellite imagery for the main economic crops in Thailand as follows:
   (i) para rubber, (ii) corn, and (iii) pineapple. Therefore, our proposed
   MeViT enhances vision transformers (ViTs), one of the modern deep
   learning on computer vision tasks, to learn semantically rich and
   spatially precise multi-scale representations by integrating
   medium-resolution multi-branch architectures with ViTs. We revised
   mixed-scale convolutional feedforward networks (MixCFN) by incorporating
   multiple depth-wise convolution paths to extract multi-scale local
   information to balance the model's performance and efficiency. To
   evaluate the effectiveness of our proposed method, we conduct extensive
   experiments on the publicly available dataset of Thailand scenes and
   compare the results with several state-of-the-art deep learning methods.
   The experimental results demonstrate that our proposed MeViT outperforms
   existing methods and performs better in the semantic segmentation of
   Thailand scenes. The evaluation metrics used are precision, recall, F1
   score, and mean intersection over union (IoU). Among the models
   compared, MeViT, our proposed model, achieves the best performance in
   all evaluation metrics. MeViT achieves a precision of 92.22\%, a recall
   of 94.69\%, an F1 score of 93.44\%, and a mean IoU of 83.63\%. These
   results demonstrate the effectiveness of our proposed approach in
   accurately segmenting Thai Landsat-8 data. The achieved F1 score
   overall, using our proposed MeViT, is 93.44\%, which is a major
   significance of this work.},
DOI = {10.3390/rs15215124},
Article-Number = {5124},
EISSN = {2072-4292},
ResearcherID-Numbers = {Panboonyuen, Teerapong/AAO-4985-2020
   },
ORCID-Numbers = {Panboonyuen, Teerapong/0000-0001-8464-4476
   Satirapod, Chalermchon/0000-0003-2932-0334},
Unique-ID = {WOS:001099544600001},
}

@article{ WOS:001256601800001,
Author = {Ajibola, Segun and Cabral, Pedro},
Title = {A Systematic Literature Review and Bibliometric Analysis of Semantic
   Segmentation Models in Land Cover Mapping},
Journal = {REMOTE SENSING},
Year = {2024},
Volume = {16},
Number = {12},
Month = {JUN},
Abstract = {Recent advancements in deep learning have spurred the development of
   numerous novel semantic segmentation models for land cover mapping,
   showcasing exceptional performance in delineating precise boundaries and
   producing highly accurate land cover maps. However, to date, no
   systematic literature review has comprehensively examined semantic
   segmentation models in the context of land cover mapping. This paper
   addresses this gap by synthesizing recent advancements in semantic
   segmentation models for land cover mapping from 2017 to 2023, drawing
   insights on trends, data sources, model structures, and performance
   metrics based on a review of 106 articles. Our analysis identifies top
   journals in the field, including MDPI Remote Sensing, IEEE Journal of
   Selected Topics in Earth Science, and IEEE Transactions on Geoscience
   and Remote Sensing, IEEE Geoscience and Remote Sensing Letters, and
   ISPRS Journal Of Photogrammetry And Remote Sensing. We find that
   research predominantly focuses on land cover, urban areas, precision
   agriculture, environment, coastal areas, and forests. Geographically,
   35.29\% of the study areas are located in China, followed by the USA
   (11.76\%), France (5.88\%), Spain (4\%), and others. Sentinel-2,
   Sentinel-1, and Landsat satellites emerge as the most used data sources.
   Benchmark datasets such as ISPRS Vaihingen and Potsdam, LandCover.ai,
   DeepGlobe, and GID datasets are frequently employed. Model architectures
   predominantly utilize encoder-decoder and hybrid convolutional neural
   network-based structures because of their impressive performances, with
   limited adoption of transformer-based architectures due to its
   computational complexity issue and slow convergence speed. Lastly, this
   paper highlights existing key research gaps in the field to guide future
   research directions.},
DOI = {10.3390/rs16122222},
Article-Number = {2222},
EISSN = {2072-4292},
ResearcherID-Numbers = {Ajibola, Segun/LCE-5034-2024
   Cabral, Pedro/B-2616-2010},
ORCID-Numbers = {Ajibola, Segun/0000-0002-9790-6081
   Cabral, Pedro/0000-0001-8622-6008},
Unique-ID = {WOS:001256601800001},
}

@inproceedings{ WOS:000656123200125,
Author = {Kuchkorov, T. A. and Urmanov, Sh N. and Nosirov, Kh Kh},
Editor = {Li, Z and Yuan, C and Lu, J and Kerre, EE},
Title = {Perspectives of deep learning based satellite imagery analysis and
   efficient training of the U-Net architecture for land-use classification},
Booktitle = {DEVELOPMENTS OF ARTIFICIAL INTELLIGENCE TECHNOLOGIES IN COMPUTATION AND
   ROBOTICS},
Series = {World Scientific Proceedings Series on Computer Engineering and
   Information Science},
Year = {2020},
Volume = {12},
Pages = {1041-1048},
Note = {15th Symposium of Intelligent Systems and Knowledge Engineering (ISKE)
   held jointly with 14th International FLINS Conference (FLINS), Cologne,
   GERMANY, AUG 18-21, 2020},
Organization = {Fern Univ; TH Koln Univ Appl Sci; Univ Technol Sydney; SW Jiaotong Univ;
   Shunde Polytechn; Minnan Normal Univ; Natl Assoc Non Class Log \&
   Computat China},
Abstract = {A huge amount of high resolution satellite images are used in different
   fields such as environmental observation, climate forecasting, urban
   planning, public services, and precision agriculture. Especially, remote
   sensing techniques are important for land-use monitoring which is the
   most important task regarding the effective management of agricultural
   activities. And traditional object detection and classification
   algorithms are inaccurate, time wasting and unreliable to solve the
   problem and also many researchers discuss and introduce the current
   domain but still results are not good enough. Hence, this paper focuses
   on deep learning based approaches for object detection and
   classification of satellite images. This paper is devoted to
   implementation and effective training of U-Net fully convolutional
   neural network architecture for semantic segmentation of satellite
   imagery.},
ISBN = {978-981-122-333-4},
ResearcherID-Numbers = {Kuchkorov, Temurbek/V-7947-2017
   Nosirov, Khabibullo/R-3140-2016},
Unique-ID = {WOS:000656123200125},
}

@inproceedings{ WOS:001139095400061,
Author = {Hu, Haiyang and Yang, Linnan and Chen, Jiaojiao and Luo, Shuang},
Book-Group-Author = {IEEE},
Title = {The remote sensing image segmentation of land cover based on multi-scale
   attention features},
Booktitle = {2023 IEEE 35TH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL
   INTELLIGENCE, ICTAI},
Series = {Proceedings-International Conference on Tools With Artificial
   Intelligence},
Year = {2023},
Pages = {429-436},
Note = {35th IEEE International Conference on Tools with Artificial Intelligence
   (ICTAI), Atlanta, GA, NOV 06-08, 2023},
Organization = {IEEE; IEEE Comp Soc; Biol \& Artificial Intelligence Fdn},
Abstract = {Segmentation of land cover in remote sensing images is a task that
   involves interpreting remote sensing data using machine vision.
   Satisfying segmentation results in agriculture and forestry regions can
   guide land resource management, natural environment protection, urban
   construction, and the distribution of agricultural products. However,
   the performance of the widely used deep learning segmentation model on
   high-resolution remote sensing segmentation datasets in agriculture and
   forestry regions needs to be improved. To solve the problems of poor
   accuracy and loss of context information in remote sensing image
   semantic segmentation, this paper proposes an improved semantic
   segmentation network architecture. The model utilizes multi-scale
   feature extraction, deploys a multi-layer attention feature fusion
   module and an up-sampling fusion module to capture high-quality
   multi-scale context information, correctly handle scale changes, and
   help narrow the semantic gap between different levels. Finally, the
   proposed MLP decoder refers to the dynamic up-sampling operator to
   aggregate the information at different levels to achieve pixel
   segmentation. To verify the effectiveness of our proposed model, the
   researchers conducted experiments on two land cover segmentation
   datasets. The training process specifically designs data augmentation
   strategies for remote sensing segmentation tasks to enhance the model's
   generalization ability. The final model achieved an mIoU (mean
   Intersection over Union) of 65.05\% on the self-built rural land cover
   datasets, surpassing the benchmark network UPerNet by 5.92\%. On the
   LoveDA dataset, our model achieved state-of-the-art performance with an
   mIoU of 53.39\%, demonstrating its versatility.},
DOI = {10.1109/ICTAI59109.2023.00069},
ISSN = {1082-3409},
ISBN = {979-8-3503-4273-4},
ResearcherID-Numbers = {Hu, Haiyang/AAT-1326-2021
   chen, jiaojiao/KII-6749-2024},
Unique-ID = {WOS:001139095400061},
}

@article{ WOS:001187053300001,
Author = {Li, Jiangyun and Cai, Yuanxiu and Li, Qing and Kou, Mingyin and Zhang,
   Tianxiang},
Title = {A review of remote sensing image segmentation by deep learning methods},
Journal = {INTERNATIONAL JOURNAL OF DIGITAL EARTH},
Year = {2024},
Volume = {17},
Number = {1},
Month = {DEC 31},
Abstract = {Remote sensing (RS) images enable high-resolution information collection
   from complex ground objects and are increasingly utilized in the earth
   observation research. Recently, RS technologies are continuously
   enhanced by various characterized platforms and sensors. Simultaneously,
   artificial intelligence vision algorithms are also developing vigorously
   and playing a significant role in RS image analysis. In particular,
   aiming to divide images into different ground elements with specific
   semantic labels, RS image segmentation could realize the visual
   acquisition and interpretation. As one of the pioneering methods with
   the advantages of deep feature extraction ability, deep learning (DL)
   algorithms have been exploited and proved to be highly beneficial for
   precise segmentation in recent years. In this paper, a comprehensive
   review is performed on remote sensing survey systems and various kinds
   of specially designed deep learning architectures. Meanwhile, DL-based
   segmentation methods applied on four domains are also illustrated,
   including geography, precision agriculture, hydrology, and environmental
   protection issues. In the end, the existing challenges and promising
   research directions in RS image segmentation are discussed. It is
   envisioned that this review is able to provide a comprehensive and
   technical reference, deployment and successful exploitation of DL
   empowered RS image segmentation approaches.},
DOI = {10.1080/17538947.2024.2328827},
Article-Number = {2328827},
ISSN = {1753-8947},
EISSN = {1753-8955},
ResearcherID-Numbers = {Kou, Mingyin/Y-6957-2018
   Zhang, Tianxiang/MZQ-3567-2025
   },
ORCID-Numbers = {Zhang, Tianxiang/0000-0002-0996-2586},
Unique-ID = {WOS:001187053300001},
}

@article{ WOS:000902682400001,
Author = {Safarov, Furkat and Temurbek, Kuchkorov and Jamoljon, Djumanov and
   Temur, Ochilov and Chedjou, Jean Chamberlain and Abdusalomov, Akmalbek
   Bobomirzaevich and Cho, Young-Im},
Title = {Improved Agricultural Field Segmentation in Satellite Imagery Using
   TL-ResUNet Architecture},
Journal = {SENSORS},
Year = {2022},
Volume = {22},
Number = {24},
Month = {DEC},
Abstract = {Currently, there is a growing population around the world, and this is
   particularly true in developing countries, where food security is
   becoming a major problem. Therefore, agricultural land monitoring, land
   use classification and analysis, and achieving high yields through
   efficient land use are important research topics in precision
   agriculture. Deep learning-based algorithms for the classification of
   satellite images provide more reliable and accurate results than
   traditional classification algorithms. In this study, we propose a
   transfer learning based residual UNet architecture (TL-ResUNet) model,
   which is a semantic segmentation deep neural network model of land cover
   classification and segmentation using satellite images. The proposed
   model combines the strengths of residual network, transfer learning, and
   UNet architecture. We tested the model on public datasets such as
   DeepGlobe, and the results showed that our proposed model outperforms
   the classic models initiated with random weights and pre-trained
   ImageNet coefficients. The TL-ResUNet model outperforms other models on
   several metrics commonly used as accuracy and performance measures for
   semantic segmentation tasks. Particularly, we obtained an IoU score of
   0.81 on the validation subset of the DeepGlobe dataset for the
   TL-ResUNet model.},
DOI = {10.3390/s22249784},
Article-Number = {9784},
EISSN = {1424-8220},
ResearcherID-Numbers = {Abdusalomov, Akmalbek/AEB-6319-2022
   FURKAT, SAFAROV/LQJ-5265-2024
   },
ORCID-Numbers = {Safarov, Furkat/0000-0002-6612-8176
   Chedjou, Jean Chamberlain/0000-0002-5675-4747
   Cho, Young Im/0000-0003-0184-7599
   Djumanov, Olimjon/0009-0005-9771-8645
   Abdusalomov, Akmalbek/0000-0001-5923-8695
   Ochilov, Temur/0000-0003-1707-4316
   Kuchkorov, Temurbek/0000-0003-4041-1843},
Unique-ID = {WOS:000902682400001},
}

@inproceedings{ WOS:000474419500050,
Author = {Liu, Xinni and Han, Fengrong and Ghazali, Kamarul Hawari and Mohamed,
   Izzeldin Ibrahim and Zhao, Yue},
Book-Group-Author = {ACM},
Title = {A review of Convolutional Neural Networks in Remote Sensing Image},
Booktitle = {2019 8TH INTERNATIONAL CONFERENCE ON SOFTWARE AND COMPUTER APPLICATIONS
   (ICSCA 2019)},
Year = {2019},
Pages = {263-267},
Note = {8th International Conference on Software and Computer Applications
   (ICSCA), Penang, MALAYSIA, FEB 19-21, 2019},
Organization = {Univ Malaysia Pahang},
Abstract = {Effectively analysis of remote-sensing images is very important in many
   practical applications, such as urban planning, geospatial object
   detection, military monitoring, vegetation mapping and precision
   agriculture. Recently, convolutional neural network based deep learning
   algorithm has achieved a series of breakthrough research results in the
   fields of objective detection, image semantic segmentation and image
   classification, etc. Their powerful feature learning capabilities have
   attracted more attention and have important research value. In this
   article, firstly we have summarized the basic structure and several
   classical convolutional neural network architectures. Secondly, the
   recent research problems on convolutional neural network are discussed.
   Later, we summarized the latest research results in convolutional neural
   network based remote sensing fields. Finally, the conclusion has made on
   the basis of current issue on convolutional neural networks and the
   future development direction.},
DOI = {10.1145/3316615.3316712},
ISBN = {978-1-4503-6573-4},
ResearcherID-Numbers = {Mohamed, Izzeldin Ibrahim/AFJ-9817-2022},
Unique-ID = {WOS:000474419500050},
}

@article{ WOS:000566127500001,
Author = {Zhang, Yunfeng and Chi, Mingmin},
Title = {Mask-R-FCN: A Deep Fusion Network for Semantic Segmentation},
Journal = {IEEE ACCESS},
Year = {2020},
Volume = {8},
Pages = {155753-155765},
Abstract = {Remote sensing image classification plays a significant role in urban
   applications, precision agriculture, water resource management. The task
   of classification in the field of remote sensing is to map raw images to
   semantic maps. Typically, fully convolutional network (FCN) is one of
   the most effective deep neural networks for semantic segmentation.
   However, small objects in remote sensing images can be easily overlooked
   and misclassified as the majority label, which is often the background
   of the image. Although many works have attempted to deal with this
   problem, making a trade-off between background semantics and edge
   details is still a problem. This is mainly because they are based on a
   single neural network model. To deal with this problem, a convolutional
   deep network with regions (R-CNN), which is highly effective for object
   detection is leveraged as a complementary component in our work. A
   learning-based and decision-level strategy is applied to fuse both
   semantic maps from a semantic model and an object detection model. The
   proposed network is referred to as Mask-R-FCN. Experimental results on
   real remote sensing images from the Zurich dataset, Gaofen Image Dataset
   (GID), and DataFountain2017 show that the proposed network can obtain
   higher accuracy than single deep neural networks and other machine
   learning algorithms. The proposed network achieved better average
   accuracies, which are approximately 2\% higher than those of any other
   single deep neural networks on the Zurich, GID, and DataFoundation2017
   datasets.},
DOI = {10.1109/ACCESS.2020.3012701},
ISSN = {2169-3536},
ResearcherID-Numbers = {Chi, Mingmin/HDO-3276-2022},
Unique-ID = {WOS:000566127500001},
}

@article{ WOS:000697168200006,
Author = {Li, Rui and Zheng, Shunyi and Zhang, Ce and Duan, Chenxi and Wang, Libo
   and Atkinson, Peter M.},
Title = {ABCNet: Attentive bilateral contextual network for efficient semantic
   segmentation of Fine-Resolution remotely sensed imagery},
Journal = {ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING},
Year = {2021},
Volume = {181},
Pages = {84-98},
Month = {NOV},
Abstract = {Semantic segmentation of remotely sensed imagery plays a critical role
   in many real-world applications, such as environmental change
   monitoring, precision agriculture, environmental protection, and
   economic assessment. Following rapid developments in sensor
   technologies, vast numbers of fine-resolution satellite and airborne
   remote sensing images are now available, for which semantic segmentation
   is potentially a valuable method. However, because of the rich
   complexity and heterogeneity of information provided with an
   ever-increasing spatial resolution, state-of-the-art deep learning
   algorithms commonly adopt complex network structures for segmentation,
   which often result in significant computational demand. Particularly,
   the frequently-used fully convolutional network (FCN) relies heavily on
   fine-grained spatial detail (fine spatial resolution) and contextual
   information (large receptive fields), both imposing high computational
   costs. This impedes the practical utility of FCN for real-world
   applications, especially those requiring real-time data processing. In
   this paper, we propose a novel Attentive Bilateral Contextual Network
   (ABCNet), a lightweight convolutional neural network (CNN) with a
   spatial path and a contextual path. Extensive experiments, including a
   comprehensive ablation study, demonstrate that ABCNet has strong
   discrimination capability with competitive accuracy compared with
   stateof-the-art benchmark methods while achieving significantly
   increased computational efficiency. Specifically, the proposed ABCNet
   achieves a 91.3\% overall accuracy (OA) on the Potsdam test dataset and
   outperforms all lightweight benchmark methods significantly. The code is
   freely available at https;//github.com./lironui/ABCNet.},
DOI = {10.1016/j.isprsjprs.2021.09.005},
EarlyAccessDate = {SEP 2021},
ISSN = {0924-2716},
EISSN = {1872-8235},
ResearcherID-Numbers = {ATKINSON, PETER/JMC-0348-2023
   Zhang, Ce/J-4906-2019
   Zheng, Si/X-1120-2019
   Li, Rui/ADH-9550-2022
   Wang, Libo/GLR-6297-2022
   Atkinson, Peter/JOZ-0803-2023
   },
ORCID-Numbers = {LI, RUI/0000-0001-7858-3160
   Wang, Libo/0000-0001-8096-6531
   Atkinson, Peter/0000-0002-5489-6880
   Zhang, Ce/0000-0001-5100-3584},
Unique-ID = {WOS:000697168200006},
}

@inproceedings{ WOS:001155034200022,
Author = {Cao, Yiwen and Jiang, Nanfeng and Wang, Da-Han and Wu, Yun and Zhu,
   Shunzhi},
Editor = {Liu, Q and Wang, H and Ma, Z and Zheng, W and Zha, H and Chen, X and Wang, L and Ji, R},
Title = {UAM-Net: An Attention-Based Multi-level Feature Fusion UNet for Remote
   Sensing Image Segmentation},
Booktitle = {PATTERN RECOGNITION AND COMPUTER VISION, PRCV 2023, PT IV},
Series = {Lecture Notes in Computer Science},
Year = {2024},
Volume = {14428},
Pages = {267-278},
Note = {6th Chinese Conference on Pattern Recognition and Computer Vision
   (PRCV), Xiamen Univ, Xiamen, PEOPLES R CHINA, OCT 13-15, 2023},
Organization = {Chinese Assoc Artificial Intelligence; China Comp Federat; Chinese Assoc
   Automat; China Soc Image \& Graph},
Abstract = {Semantic segmentation of Remote Sensing Images (RSIs) is an essential
   application for precision agriculture, environmental protection, and
   economic assessment. While UNet-based networks have made significant
   progress, they still face challenges in capturing long-range
   dependencies and preserving fine-grained details. To address these
   limitations and improve segmentation accuracy, we propose an effective
   method, namely UAM-Net (UNet with Attention-based Multi-level feature
   fusion), to enhance global contextual understanding and maintain
   fine-grained information. To be specific, UAM-Net incorporates three key
   modules. Firstly, the Global Context Guidance Module (GCGM) integrates
   semantic information from the Pyramid Pooling Module (PPM) into each
   decoder stage. Secondly, the Triple Attention Module (TAM) effectively
   addresses feature discrepancies between the encoder and decoder.
   Finally, the computation-effective Linear Attention Module (LAM)
   seamlessly fuses coarse-level feature maps with multiple decoder stages.
   With the corporations of these modules, UAM-Net significantly
   outperforms the most state-of-the-art methods on two popular benchmarks.},
DOI = {10.1007/978-981-99-8462-6\_22},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-981-99-8461-9; 978-981-99-8462-6},
ResearcherID-Numbers = {Jiang, Nanfeng/AEO-9860-2022},
Unique-ID = {WOS:001155034200022},
}

@article{ WOS:000597522700001,
Author = {Graf, Lukas and Bach, Heike and Tiede, Dirk},
Title = {Semantic Segmentation of Sentinel-2 Imagery for Mapping Irrigation
   Center Pivots},
Journal = {REMOTE SENSING},
Year = {2020},
Volume = {12},
Number = {23},
Month = {DEC},
Abstract = {Estimating the number and size of irrigation center pivot systems (CPS)
   from remotely sensed data, using artificial intelligence (AI), is a
   potential information source for assessing agricultural water use. In
   this study, we identified two technical challenges in the
   neural-network-based classification: Firstly, an effective reduction of
   the feature space of the remote sensing data to shorten training times
   and increase classification accuracy is required. Secondly, the
   geographical transferability of the AI algorithms is a pressing issue if
   AI is to replace human mapping efforts one day. Therefore, we trained
   the semantic image segmentation algorithm U-NET on four spectral
   channels (U-NET SPECS) and the first three principal components (U-NET
   principal component analysis (PCA)) of ESA/Copernicus Sentinel-2 images
   on a study area in Texas, USA, and assessed the geographic
   transferability of the trained models to two other sites: the Duero
   basin, in Spain, and South Africa. U-NET SPECS outperformed U-NET PCA at
   all three study areas, with the highest f1-score at Texas (0.87, U-NET
   PCA: 0.83), and a value of 0.68 (U-NET PCA: 0.43) in South Africa. At
   the Duero, both models showed poor classification accuracy (f1-score
   U-NET PCA: 0.08; U-NET SPECS: 0.16) and segmentation quality, which was
   particularly evident in the incomplete representation of the center
   pivot geometries. In South Africa and at the Duero site, a high rate of
   false positive and false negative was observed, which made the model
   less useful, especially at the Duero test site. Thus, geographical
   invariance is not an inherent model property and seems to be mainly
   driven by the complexity of land-use pattern. We do not consider PCA a
   suited spectral dimensionality reduction measure in this. However,
   shorter training times and a more stable training process indicate
   promising prospects for reducing computational burdens. We therefore
   conclude that effective dimensionality reduction and geographic
   transferability are important prospects for further research towards the
   operational usage of deep learning algorithms, not only regarding the
   mapping of CPS.},
DOI = {10.3390/rs12233937},
Article-Number = {3937},
EISSN = {2072-4292},
ResearcherID-Numbers = {Graf, Lukas/AAG-3509-2019
   Tiede, Dirk/ABE-9284-2020
   },
ORCID-Numbers = {Tiede, Dirk/0000-0002-5473-3344
   Graf, Lukas/0000-0003-4800-8258},
Unique-ID = {WOS:000597522700001},
}

@article{ WOS:001292251500001,
Author = {Xu, Fan and Yao, Xiaochuang and Zhang, Kangxin and Yang, Hao and Feng,
   Quanlong and Li, Ying and Yan, Shuai and Gao, Bingbo and Li, Shaoshuai
   and Yang, Jianyu and Zhang, Chao and Lv, Yahui and Zhu, Dehai and Ye,
   Sijing},
Title = {Deep learning in cropland field identification: A review},
Journal = {COMPUTERS AND ELECTRONICS IN AGRICULTURE},
Year = {2024},
Volume = {222},
Month = {JUL},
Abstract = {The cropland field (CF) is the basic unit of agricultural production and
   a key element of precision agriculture. High-precision delineations of
   CF boundaries provide a reliable data foundation for field labor and
   mechanized operations. In recent years, with the dual advancements in
   remote sensing satellite technology and artificial intelligence,
   enabling the extraction of CF information on a wide scale and with high
   precision, research on CF identification based on deep learning (DL) has
   emerged as a highly esteemed direction in this field. To comprehend the
   developmental trends within this field, this study employs bibliometric
   and content analysis methods to comprehensively review and analyze DL
   research in the field of CF identification from various perspectives.
   Initially, 93 relevant literature pieces were retrieved and screened
   from two databases, the Web of Science Core Collection and the Chinese
   Science Citation Database, for review. The previous studies underwent
   quantitative analysis using bibliometric software across five
   dimensions: publication year, literature type and publication journal,
   country, author, and keyword. Subsequently, we analyze the current
   status and trends of employing DL in the field of CF identification from
   four perspectives: remote sensing data sources, DL models, types of CF
   extraction results, and sample datasets. Simultaneously, we combed
   through current publicly available sample datasets and data products
   that can be referenced to produce sample datasets for CFs. Finally, the
   challenges and future research focus of DL-based CF identification
   research are discussed. This paper provides both qualitative and
   quantitative analyses of research on DL-based CF identification,
   elucidating the current status, development trends, challenges, and
   future research focuses.},
DOI = {10.1016/j.compag.2024.109042},
EarlyAccessDate = {MAY 2024},
Article-Number = {109042},
ISSN = {0168-1699},
EISSN = {1872-7107},
ResearcherID-Numbers = {li, ying/IQS-8071-2023
   Yao, Xiaochuang/ACD-7030-2022
   },
ORCID-Numbers = {Xu, Fan/0009-0009-4272-8693},
Unique-ID = {WOS:001292251500001},
}

@article{ WOS:000839911700001,
Author = {Huang, Yuhan and Jin, Yufang},
Title = {Aerial Imagery-Based Building Footprint Detection with an Integrated
   Deep Learning Framework: Applications for Fine Scale Wildland-Urban
   Interface Mapping},
Journal = {REMOTE SENSING},
Year = {2022},
Volume = {14},
Number = {15},
Month = {AUG},
Abstract = {Human encroachment into wildlands has resulted in a rapid increase in
   wildland-urban interface (WUI) expansion, exposing more buildings and
   population to wildfire risks. More frequent mapping of structures and
   WUIs at a finer spatial resolution is needed for WUI characterization
   and hazard assessment. However, most approaches rely on high-resolution
   commercial satellite data with a particular focus on urban areas. We
   developed a deep learning framework tailored for building footprint
   detection in the transitional wildland-urban areas. We leveraged meter
   scale aerial imageries publicly available from the National Agriculture
   Imagery Program (NAIP) every 2 years. Our approach integrated
   Mobile-UNet and generative adversarial network. The deep learning models
   trained over three counties in California performed well in detecting
   building footprints across diverse landscapes, with an F1 score of 0.62,
   0.67, and 0.75 in the interface WUI, intermix WUI, and rural regions,
   respectively. The bi-annual mapping captured both housing expansion and
   wildfire-caused building damages. The 30 m WUI maps generated from these
   finer footprints showed more granularity than the existing census
   tract-based maps and captured the transition of WUI dynamics well. More
   frequent updates of building footprint and improved WUI mapping will
   improve our understanding of WUI dynamics and provide guidance for
   adaptive strategies on community planning and wildfire hazard reduction.},
DOI = {10.3390/rs14153622},
Article-Number = {3622},
EISSN = {2072-4292},
ResearcherID-Numbers = {Huang, Yuhan/J-9715-2019
   },
ORCID-Numbers = {Huang, Yuhan/0000-0001-7478-1442},
Unique-ID = {WOS:000839911700001},
}

@article{ WOS:000662566500001,
Author = {Wang, Lin and Zhou, Yuzhen and Hu, Qiao and Tang, Zhenghong and Ge,
   Yufeng and Smith, Adam and Awada, Tala and Shi, Yeyin},
Title = {Early Detection of Encroaching Woody Juniperus virginiana and Its
   Classification in Multi-Species Forest Using UAS Imagery and Semantic
   Segmentation Algorithms},
Journal = {REMOTE SENSING},
Year = {2021},
Volume = {13},
Number = {10},
Month = {MAY},
Abstract = {Woody plant encroachment into grasslands ecosystems causes significantly
   ecological destruction and economic losses. Effective and efficient
   management largely benefits from accurate and timely detection of
   encroaching species at an early development stage. Recent advances in
   unmanned aircraft systems (UAS) enabled easier access to ultra-high
   spatial resolution images at a centimeter level, together with the
   latest machine learning based image segmentation algorithms, making it
   possible to detect small-sized individuals of target species at early
   development stage and identify them when mixed with other species.
   However, few studies have investigated the optimal practical spatial
   resolution of early encroaching species detection. Hence, we
   investigated the performance of four popular semantic segmentation
   algorithms (decision tree, DT; random forest, RF; AlexNet; and ResNet)
   on a multi-species forest classification case with UAS-collected RGB
   images in original and down-sampled coarser spatial resolutions. The
   objective of this study was to explore the optimal segmentation
   algorithm and spatial resolution for eastern redcedar (Juniperus
   virginiana, ERC) early detection and its classification within a
   multi-species forest context. To be specific, firstly, we implemented
   and compared the performance of the four semantic segmentation
   algorithms with images in the original spatial resolution (0.694 cm).
   The highest overall accuracy was 0.918 achieved by ResNet with a mean
   interaction over union at 85.0\%. Secondly, we evaluated the performance
   of ResNet algorithm with images in down-sampled spatial resolutions (1
   cm to 5 cm with 0.5 cm interval). When applied on the down-sampled
   images, ERC segmentation performance decreased with decreasing spatial
   resolution, especially for those images coarser than 3 cm spatial
   resolution. The UAS together with the state-of-the-art semantic
   segmentation algorithms provides a promising tool for early-stage
   detection and localization of ERC and the development of effective
   management strategies for mixed-species forest management.},
DOI = {10.3390/rs13101975},
Article-Number = {1975},
EISSN = {2072-4292},
ResearcherID-Numbers = {Wang, Lin/HJP-0545-2023
   },
ORCID-Numbers = {Wang, Lin/0000-0002-0034-1732
   Shi, Yeyin/0000-0003-3964-2855},
Unique-ID = {WOS:000662566500001},
}

@article{ WOS:001457023300001,
Author = {Shokati, Hadi and Engelhardt, Andreas and Seufferheld, Kay and
   Taghizadeh-Mehrjardi, Ruhollah and Fiener, Peter and Lensch, Hendrik P.
   A. and Scholten, Thomas},
Title = {Erosion-SAM: Semantic segmentation of soil erosion by water},
Journal = {CATENA},
Year = {2025},
Volume = {254},
Month = {JUN 30},
Abstract = {Soil erosion (SE) by water threatens global agriculture by depleting
   fertile topsoil and causing economic costs. Conventional SE models
   struggle to capture the complex, non-linear interactions between SE
   drivers. Recently, machine learning has gained attention for SE
   modeling. However, machine learning requires large data sets for
   effective training and validation. In this study, we present
   Erosion-SAM, which fine-tunes the Segment Anything Model (SAM) for
   automatic segmentation of water erosion features in high-resolution
   remote sensing imagery. The data set comprised 405 manually segmented
   agricultural fields from erosion-prone areas obtained from the rain
   gauge-adjusted radar rainfall data (RADOLAN) for bare cropland,
   vegetated cropland, and grassland. Three approaches were evaluated: two
   pre-processing techniques- resizing and cropping - and an improved
   version of the resizing approach with user-defined prompts during the
   testing phase. All fine-tuned models outperformed the original SAM, with
   the prompt-based resizing method showing the highest accuracy,
   especially for grassland (recall: 0.90, precision: 0.82, dice
   coefficient: 0.86, IoU: 0.75). SAM performed better than the cropping
   approach only on bare cropland. This discrepancy is attributed to the
   tendency of SAM to overestimate SE by classifying a large proportion of
   fields as eroded, which increases recall by covering most of the eroded
   pixels. All three fine-tuned approaches showed strong correlations with
   the actual SE severity ratios, with the prompt-enhanced resizing
   approach achieving the highest R-2 of 0.93. In summary, Erosion-SAM
   shows promising potential for automatically detecting SE features from
   remote sensing images. The generated data sets can be applied to machine
   learning-based SE modeling, providing accurate and consistent training
   data across different land cover types, and offering a reliable
   alternative to traditional SE models. In addition, erosion-SAM can make
   a valuable contribution to the precise monitoring of SE with high
   temporal resolution over large areas, and its results could benefit
   reinsurance and insurance-related risk solutions.},
DOI = {10.1016/j.catena.2025.108954},
EarlyAccessDate = {MAR 2025},
Article-Number = {108954},
ISSN = {0341-8162},
EISSN = {1872-6887},
ResearcherID-Numbers = {Seufferheld, Kay/JNS-5344-2023
   Scholten, Thomas/E-4024-2012},
Unique-ID = {WOS:001457023300001},
}

@inproceedings{ WOS:000468823900085,
Author = {Xia, Liegang and Luo, Jiancheng and Sun, Yingwei and Yang, Haiping},
Book-Group-Author = {IEEE},
Title = {Deep Extraction of Cropland Parcels from Very High-Resolution Remotely
   Sensed Imagery},
Booktitle = {2018 7TH INTERNATIONAL CONFERENCE ON AGRO-GEOINFORMATICS
   (AGRO-GEOINFORMATICS)},
Series = {International Conference on Agro-Geoinformatics},
Year = {2018},
Pages = {405-409},
Note = {7th International Conference on Agro-Geoinformatics
   (Agro-Geoinformatics), George Mason Univ, Ctr Spatial Informat Sci \&
   Syst, Hangzhou, PEOPLES R CHINA, AUG 06-09, 2018},
Organization = {Ctr Spatial Informat Sci \& Syst Fdn Inc; United States Dept Agr NIFA;
   Zhejiang Univ; China Agr Univ; IEEE GRASS; Chinese Acad Agr Sci; IARRP
   CASS; Open Geospatial Consoritium; TARBIL; United States Dept Agr;
   United States Dept Agr Agr Res Serv},
Abstract = {Extracting cropland parcels from high resolution remote sensing images
   is a basic task for precision agriculture and other fields. Object based
   image analysis rely heavily on segmentation methods and can't satisfy
   the parcels' requisition in most situation. Inspired by the recent
   remarkable improvement on image understanding with deep learning, we
   propose a deep-edge guided method for cropland parcels extraction. Focus
   on the boundaries of these parcels, hard edge and soft edge are
   extracted respectively with U-Net and RCF model. Then all edges with the
   land type of cropland are constructed into parcels. At last accurate
   cropland-parcels are achieved.},
ISSN = {2334-3168},
ResearcherID-Numbers = {Liu, Yihao/GOK-0831-2022},
Unique-ID = {WOS:000468823900085},
}

@article{ WOS:000550845400001,
Author = {de Albuquerque, Anesmar Olino and de Carvalho Junior, Osmar Abilio and
   Ferreira de Carvalho, Osmar Luiz and de Bem, Pablo Pozzobon and
   Guimaraes Ferreira, Pedro Henrique and de Moura, Rebeca dos Santos and
   Silva, Cristiano Rosa and Trancoso Gomes, Roberto Arnaldo and Guimaraes,
   Renato Fontes},
Title = {Deep Semantic Segmentation of Center Pivot Irrigation Systems from
   Remotely Sensed Data},
Journal = {REMOTE SENSING},
Year = {2020},
Volume = {12},
Number = {13},
Month = {JUL},
Abstract = {The center pivot irrigation system (CPIS) is a modern irrigation
   technique widely used in precision agriculture due to its high
   efficiency in water consumption and low labor compared to traditional
   irrigation methods. The CPIS is a leader in mechanized irrigation in
   Brazil, with growth forecast for the coming years. Therefore, the
   mapping of center pivot areas is a strategic factor for the estimation
   of agricultural production, ensuring food security, water resources
   management, and environmental conservation. In this regard, digital
   processing of satellite images is the primary tool allowing regional and
   continuous monitoring with low costs and agility. However, the automatic
   detection of CPIS using remote sensing images remains a challenge, and
   much research has adopted visual interpretation. Although CPIS presents
   a consistent circular shape in the landscape, these areas can have a
   high internal variation with different plantations that vary over time,
   which is difficult with just the spectral behavior. Deep learning using
   convolutional neural networks (CNNs) is an emerging approach that
   provokes a revolution in image segmentation, surpassing traditional
   methods, and achieving higher accuracy and efficiency. This research
   aimed to evaluate the use of deep semantic segmentation of CPIS from
   CNN-based algorithms using Landsat-8 surface reflectance images (seven
   bands). The developed methodology can be subdivided into the following
   steps: (a) Definition of three study areas with a high concentration of
   CPIS in Central Brazil; (b) acquisition of Landsat-8 images considering
   the seasonal variations of the rain and drought periods; (c) definition
   of CPIS datasets containing Landsat images and ground truth mask of
   256x256 pixels; (d) training using three CNN architectures (U-net, Deep
   ResUnet, and SharpMask); (e) accuracy analysis; and (f) large image
   reconstruction using six stride values (8, 16, 32, 64, 128, and 256).
   The three methods achieved state-of-the-art results with a slight
   prevalence of U-net over Deep ResUnet and SharpMask (0.96, 0.95, and
   0.92 Kappa coefficients, respectively). A novelty in this research was
   the overlapping pixel analysis in the large image reconstruction. Lower
   stride values had improvements quantified by the Receiver Operating
   Characteristic curve (ROC curve) and Kappa, and fewer errors in the
   frame edges were also perceptible. The overlapping images significantly
   improved the accuracy and reduced the error present in the edges of the
   classified frames. Additionally, we obtained greater accuracy results
   during the beginning of the dry season. The present study enabled the
   establishment of a database of center pivot images and an adequate
   methodology for mapping the center pivot in central Brazil.},
DOI = {10.3390/rs12132159},
Article-Number = {2159},
EISSN = {2072-4292},
ResearcherID-Numbers = {de, Pablo/AAW-5619-2020
   Gomes, Roberto/AAI-3379-2020
   Carvalho, Osmar/ABA-5267-2021
   de Carvalho Junior, Osmar Abilio/AAK-4880-2021
   Guimaraes, Renato/C-4601-2013},
ORCID-Numbers = {ALBUQUERQUE, ANESMAR OLINO DE/0000-0003-1561-7583
   de Bem, Pablo/0000-0003-3868-8704
   Moura, Rebeca/0000-0002-7685-8826
   Trancoso Gomes, Roberto Arnaldo/0000-0003-4724-4064
   de Carvalho Junior, Osmar Abilio/0000-0002-0346-1684
   Carvalho, Osmar Luiz/0000-0002-5619-8525
   Guimaraes, Renato/0000-0002-9555-043X},
Unique-ID = {WOS:000550845400001},
}

@article{ WOS:001129019400001,
Author = {Lv, Zhonghui and Nunez, Karinna and Brewer, Ethan and Runfola, Dan},
Title = {Mapping the tidal marshes of coastal Virginia: a hierarchical transfer
   learning approach},
Journal = {GISCIENCE \& REMOTE SENSING},
Year = {2024},
Volume = {61},
Number = {1},
Month = {DEC 31},
Abstract = {Coastal wetlands, especially tidal marshes, play a crucial role in
   supporting ecosystems and slowing shoreline erosion. Accurate and
   cost-effective identification and classification of various marsh types,
   such as high and low marshes, are important for effective coastal
   management and conservation endeavors. However, mapping tidal marshes is
   challenging due to heterogeneous coastal vegetation and dynamic tidal
   influences. In this study, we employ a deep learning segmentation model
   to automate the identification and classification of tidal marsh
   communities in coastal Virginia, USA, using seasonal, publicly available
   satellite and aerial images. This study leverages the combined
   capabilities of Sentinel-2 and National Agriculture Imagery Program
   (NAIP) imagery and a UNet architecture to accurately classify tidal
   marsh communities. We illustrate that by leveraging features learned
   from data abundant regions and small quantities of high-quality training
   data collected from the target region, an accuracy as high as 88\% can
   be achieved in the classification of marsh types, specifically high
   marsh and low marsh, at a spatial resolution of 0.6 m. This study
   contributes to the field of marsh mapping by highlighting the potential
   of combining multispectral satellite imagery and deep learning for
   accurate and efficient marsh type classification.},
DOI = {10.1080/15481603.2023.2287291},
Article-Number = {2287291},
ISSN = {1548-1603},
EISSN = {1943-7226},
ResearcherID-Numbers = {Runfola, Daniel/AAI-7868-2020
   Lv, Zhonghui/AAT-5065-2021
   },
ORCID-Numbers = {Miller Runfola, Daniel/0000-0001-5356-4676
   Lv, Zhonghui/0000-0001-5186-3699},
Unique-ID = {WOS:001129019400001},
}

@article{ WOS:000719642200001,
Author = {de Bem, Pablo Pozzobon and de Carvalho Junior, Osmar Abilio and Ferreira
   de Carvalho, Osmar Luiz and Trancoso Gomes, Roberto Arnaldo and
   Guimaraes, Renato Fontes and McManus Pimentel, Concepta Margaret},
Title = {Irrigated rice crop identification in Southern Brazil using
   convolutional neural networks and Sentinel-1 time series},
Journal = {REMOTE SENSING APPLICATIONS-SOCIETY AND ENVIRONMENT},
Year = {2021},
Volume = {24},
Month = {NOV},
Abstract = {Rice is one of the world's staple food sources, with millions of tonnes
   produced and consumed every year. Therefore, mapping rice paddies is
   essential for agricultural management and ensuring food security. This
   study aimed to classify rice crops in southern Brazil using the
   SENTINEL-1 SAR time series and deep learning models, comparing two
   architectures (U-net and LinkNet) and four backbones (ResNet-34,
   ResNeXt-50, DenseNet-121, and VGG16). The time series construction
   considered ten images, each for a month, covering the rice planting
   cycle. The Convolutional Neural Network architectures were adapted to
   use multi-band data, allowing the extraction of features from
   all-temporal images. This approach provides capturing spatiotemporal
   information from rice plantations, which favors its detection. Besides,
   the research evaluated three data sets considering the polarizations:
   (a) VV-only, (b) VH-only, and (c) both VV and VH (VV + VH). The
   classification accuracies used to measure the performance of the models
   were the overall accuracy, F1-measure, area under the precision-recall
   curve (AUPRC), and the intersection over union (IoU). Results show that
   the VH + VV polarization combination yielded the best results, followed
   by VH-only and VV-only. The VV-only polarization had significantly worst
   results (nearly 10\% less IoU than VH-only and nearly 15\% less IoU
   compared to VV + VH). The results show that rice fields can be
   successfully classified with deep learning models and through our
   evaluation the LinkNet architecture with the ResNeXt-50 backbone showed
   the best results with an accuracy of 0.98, F1 of 0.93, AUPRC of 0.93,
   and IoU of 0.91.},
DOI = {10.1016/j.rsase.2021.100627},
EarlyAccessDate = {SEP 2021},
Article-Number = {100627},
ISSN = {2352-9385},
ResearcherID-Numbers = {McManus, Connie/I-4356-2012
   Gomes, Roberto/AAI-3379-2020
   de, Pablo/AAW-5619-2020
   Carvalho, Osmar/ABA-5267-2021
   Guimaraes, Renato/C-4601-2013
   de Carvalho Junior, Osmar Abilio/AAK-4880-2021
   },
ORCID-Numbers = {de Carvalho Junior, Osmar Abilio/0000-0002-0346-1684
   de Bem, Pablo/0000-0003-3868-8704},
Unique-ID = {WOS:000719642200001},
}

@article{ WOS:001442114900001,
Author = {Parajuli, Manisha and Cristan, Richard and Daniel, Marissa Jo and Rijal,
   Arjun and Mitchell, Dana and Mcdonald, Timothy and Gallagher, Tom},
Title = {Integrating high-resolution imagery, deep learning, and GIS to estimate
   soil erosion following timber harvesting},
Journal = {REMOTE SENSING APPLICATIONS-SOCIETY AND ENVIRONMENT},
Year = {2025},
Volume = {37},
Month = {JAN},
Abstract = {Conventionally, soil erosion estimation has depended on ground-based
   methods; however, remote sensing offers a promising alternative for
   erosion estimation across various land uses and land cover classes
   (LULC). Determining erosion potential of a harvest site, considering
   different harvest categories, requires accurate segmentation of each
   category. In this study, we encompassed 20 harvest sites in the
   southeastern United States and utilized high-resolution imagery from
   unmanned aerial vehicle (UAV), geographic information system (GIS) data,
   and deep learning models to segment various harvest categories within
   each site and estimate soil erosion potential. Site data used to predict
   erosion included rainfall and runoff erosivity factor (R), soil
   erodibility factor (K), slope-length factor (L), slope-steepness factor
   (S), cover and management factor (C), and support practice factor (P).
   Six models based on U-Net, Deeplab V3, and PSPNet architectures,
   utilizing ResNet-34 and ResNet-50 backbones, were trained and evaluated
   for their accuracy in segmenting harvest categories. The model trained
   with Deeplab V3 architecture and ResNet-34 backbone demonstrated
   superior precision, recall, and F1 values compared to the others and was
   selected for segmenting the orthomosaic maps of the harvest sites into
   different harvest categories. Subsequently, using the classified
   orthomosaic and field-based data, a CP raster layer of each harvest site
   was prepared. The study revealed that roads exhibit the highest
   potential erosion rate, followed by skid trails, loading decks,
   clear-cut areas, clear-cut areas with vegetation, and streamside
   management zones (SMZs). The overall average erosion rate from all the
   harvest sites was 0.78 tonnes per hectare annually. Furthermore, the
   documented CP factor provides a time-efficient alternative for soil
   erosion estimation, reducing reliance on fieldintensive on-site
   assessments. Overall, this study demonstrates how integrating these
   advanced technologies provides a reliable and efficient approach to
   assess soil erosion potential at harvest sites.},
DOI = {10.1016/j.rsase.2025.101498},
EarlyAccessDate = {MAR 2025},
Article-Number = {101498},
ISSN = {2352-9385},
ResearcherID-Numbers = {Cristan, Richard/AAL-8792-2020
   Rijal, Arjun/IXW-6539-2023
   Parajuli, Manisha/HLP-6777-2023},
Unique-ID = {WOS:001442114900001},
}

@article{ WOS:000794625200001,
Author = {Lu, Rui and Wang, Nan and Zhang, Yanbin and Lin, Yeneng and Wu, Wenqiang
   and Shi, Zhou},
Title = {Extraction of Agricultural Fields via DASFNet with Dual Attention
   Mechanism and Multi-scale Feature Fusion in South Xinjiang, China},
Journal = {REMOTE SENSING},
Year = {2022},
Volume = {14},
Number = {9},
Month = {MAY},
Abstract = {Agricultural fields are essential in providing human beings with
   paramount food and other materials. Quick and accurate identification of
   agricultural fields from the remote sensing images is a crucial task in
   digital and precision agriculture. Deep learning methods have the
   advantages of fast and accurate image segmentation, especially for
   extracting the agricultural fields from remote sensing images. This
   paper proposed a deep neural network with a dual attention mechanism and
   a multi-scale feature fusion (Dual Attention and Scale Fusion Network,
   DASFNet) to extract the cropland from a GaoFen-2 (GF-2) image of 2017 in
   Alar, south Xinjiang, China. First, we constructed an agricultural field
   segmentation dataset from the GF-2 image. Next, seven evaluation indices
   were selected to assess the extraction accuracy, including the location
   shift, to reveal the spatial relationship and facilitate a better
   evaluation. Finally, we proposed DASFNet incorporating three ameliorated
   and novel deep learning modules with the dual attention mechanism and
   multi-scale feature fusion methods. The comparison of these modules
   indicated their effects and advantages. Compared with different
   segmentation convolutional neural networks, DASFNet achieved the best
   testing accuracy in extracting fields with an F1-score of 0.9017, an
   intersection over a union of 0.8932, a Kappa coefficient of 0.8869, and
   a location shift of 1.1752 pixels. Agricultural fields can be extracted
   automatedly and accurately using DASFNet, which reduces the manual
   record of the agricultural field information and is conducive to further
   farmland surveys, protection, and management.},
DOI = {10.3390/rs14092253},
Article-Number = {2253},
EISSN = {2072-4292},
ResearcherID-Numbers = {Lu, Rui/KCJ-8212-2024
   shi, Zhou/M-7845-2019
   Wang, Nan/HLV-7836-2023
   shi, zhou/A-2283-2015},
ORCID-Numbers = {Lu, Rui/0000-0002-0875-1939
   shi, zhou/0000-0003-3914-5402},
Unique-ID = {WOS:000794625200001},
}

@article{ WOS:000559045800001,
Author = {Xu, Wenna and Deng, Xinping and Guo, Shanxin and Chen, Jinsong and Sun,
   Luyi and Zheng, Xiaorou and Xiong, Yingfei and Shen, Yuan and Wang,
   Xiaoqin},
Title = {High-Resolution U-Net: Preserving Image Details for Cultivated Land
   Extraction},
Journal = {SENSORS},
Year = {2020},
Volume = {20},
Number = {15},
Month = {AUG},
Abstract = {Accurate and efficient extraction of cultivated land data is of great
   significance for agricultural resource monitoring and national food
   security. Deep-learning-based classification of remote-sensing images
   overcomes the two difficulties of traditional learning methods (e.g.,
   support vector machine (SVM), K-nearest neighbors (KNN), and random
   forest (RF)) when extracting the cultivated land: (1) the limited
   performance when extracting the same land-cover type with the high
   intra-class spectral variation, such as cultivated land with both
   vegetation and non-vegetation cover, and (2) the limited generalization
   ability for handling a large dataset to apply the model to different
   locations. However, the ``pooling{''} process in most deep convolutional
   networks, which attempts to enlarge the sensing field of the kernel by
   involving the upscale process, leads to significant detail loss in the
   output, including the edges, gradients, and image texture details. To
   solve this problem, in this study we proposed a new end-to-end
   extraction algorithm, a high-resolution U-Net (HRU-Net), to preserve the
   image details by improving the skip connection structure and the loss
   function of the original U-Net. The proposed HRU-Net was tested in
   Xinjiang Province, China to extract the cultivated land from Landsat
   Thematic Mapper (TM) images. The result showed that the HRU-Net achieved
   better performance (Acc: 92.81\%; kappa: 0.81; F1-score: 0.90) than the
   U-Net++ (Acc: 91.74\%; kappa: 0.79; F1-score: 0.89), the original U-Net
   (Acc: 89.83\%; kappa: 0.74; F1-score: 0.86), and the Random Forest model
   (Acc: 76.13\%; kappa: 0.48; F1-score: 0.69). The robustness of the
   proposed model for the intra-class spectral variation and the accuracy
   of the edge details were also compared, and this showed that the HRU-Net
   obtained more accurate edge details and had less influence from the
   intra-class spectral variation. The model proposed in this study can be
   further applied to other land cover types that have more spectral
   diversity and require more details of extraction.},
DOI = {10.3390/s20154064},
Article-Number = {4064},
EISSN = {1424-8220},
ResearcherID-Numbers = {Chen, Jinsong/AIE-7696-2022
   Sun, Luyi/AAM-1855-2020
   Guo, Shanxin/AAV-6414-2021
   },
ORCID-Numbers = {Xu, Wenna/0000-0002-2566-2233
   Zheng, Xiaorou/0000-0002-4941-5907
   Sun, Luyi/0000-0003-4575-0836},
Unique-ID = {WOS:000559045800001},
}

@article{ WOS:000714460800001,
Author = {Hu, Qiao and Woldt, Wayne and Neale, Christopher and Zhou, Yuzhen and
   Drahota, Jeff and Varner, Dana and Bishop, Andy and LaGrange, Ted and
   Zhang, Ligang and Tang, Zhenghong},
Title = {Utilizing unsupervised learning, multi-view imaging, and CNN-based
   attention facilitates cost-effective wetland mapping},
Journal = {REMOTE SENSING OF ENVIRONMENT},
Year = {2021},
Volume = {267},
Month = {DEC 15},
Abstract = {The combination of Unmanned/Unoccupied Aerial Vehicle (UAV) data and
   deep learning, especially convolutional neural networks (CNNs), offers
   robust new tools for precision land cover mapping. However, its
   successful application is highly dependent on local experiences that are
   rarely documented, resulting in practical limitations during
   implementation. Cost-effective deep learning frameworks for fast
   deployment are required. This study presents a deep learning adaptation
   framework, named Auto-UNet++, trying to streamline wetland mapping tasks
   (including training data labeling and organizing). The framework treats
   mapping tasks as an intact semantic segmentation pipeline and then
   integrates automatic strategies into each step to reduce human
   intervention. These automatic strategies are achieved by standard
   computer vision techniques, including multi-view (MV) imaging-highly
   overlapped UAV images over an area (for labeling/voting), unsupervised
   clustering (for labeling), multi-scale CNN (for feature extraction), and
   attention mechanism-a CNN design used to select informative features
   from input (for feature exploration/selection). The framework was tested
   on playa wetland mapping in the Rainwater Basin, Nebraska, USA, with
   multispectral UAV datasets. Generally, the multi-scale CNN mapping task
   achieved a high of 87\% overall accuracy and over 90\% accuracy in water
   delineation. The results indicate that the multi-view and attention
   strategies have the potential to improve segmentation performance, and
   together with unsupervised learning, save considerable labor/expertise.
   Interestingly, evidence shows that the band/scale attention (weight) is
   adaptively associated with the land cover percentages per input image,
   indicating spatial contexts captured. This finding highlights the
   potential usages of the attention rule in automatic feature exploration,
   selection, and model interpretation. The framework illustrating a highly
   automated deep learning deployment on small MV datasets facilitates
   cost-effective wetland cover mapping. Although limitations exist, the
   study demonstrated the possibility of where/how conventional
   segmentation pipelines can be improved in typical UAV wetland mapping
   tasks. The framework and findings are useful for similar applications
   (including non-UAV studies) that only have limited time, labor, and
   expertise to implement sophisticated semantic segmentation models.},
DOI = {10.1016/j.rse.2021.112757},
EarlyAccessDate = {OCT 2021},
Article-Number = {112757},
ISSN = {0034-4257},
EISSN = {1879-0704},
ResearcherID-Numbers = {Neale, Christopher/AAB-3578-2022
   },
ORCID-Numbers = {Zhang, Ligang/0000-0003-0772-1831},
Unique-ID = {WOS:000714460800001},
}

@article{ WOS:000754268300001,
Author = {Rauf, Usman and Qureshi, Waqar S. and Jabbar, Hamid and Zeb, Ayesha and
   Mirza, Alina and Alanazi, Eisa and Khan, Umar S. and Rashid, Nasir},
Title = {A new method for pixel classification for rice variety identification
   using spectral and time series data from Sentinel-2 satellite imagery},
Journal = {COMPUTERS AND ELECTRONICS IN AGRICULTURE},
Year = {2022},
Volume = {193},
Month = {FEB},
Abstract = {In the agriculture sector food productivity, security, and
   sustainability, imposed challenges on farmers, regulatory bodies, and
   policymakers due to increasing demand and depleting natural resources
   and environmental concerns. Rice crop holds a prominent place in
   Pakistan's agriculture sector, it is not only consumed locally but also
   exported to many countries including China. Gathering crop information
   such as variety maps, yield estimation, or etc. can help farmers,
   regulatory bodies, policymakers, and rice mills in decision-making. In
   Pakistan, crop information is collected through manual field surveys
   that require a lot of human labor, are costly, and are time-consuming.
   One cannot ignore human error and bias in the process. A new framework
   for pixel classification is proposed that uses both spectral and
   time-series data of Sentinal-2 satellite for mapping two rice varieties
   ``Basmati{''} and ``IRRI, grown in Pakistan. The data were collected
   from twelve rice fields (approx. 307 acres) of different geographical
   locations at 16-time instances to cover the complete rice-growing season
   (May-October) in 2019. A linear spectral unmixing model is used to
   determine sub-pixel information of water, soil, and vegetation content,
   which is used for labeling each pixel for supervised learning. The input
   to our classifier is a 16 x 15 image formed using 15 spectral features
   (12 spectral bands and 3 radiometric indices) of 16 carefully selected
   different time instances for each pixel. The output is a pixel-level
   classification (semantic segmentation) of each pixel into Basmati, IRRI,
   and others (soil, water, etc.). Experimental results have exhibited an
   excellent overall accuracy of 98.6\% with the proposed approach. The
   Basmati rice obtained higher accuracy of 99.7\% as compared to IRRI rice
   with an accuracy of 95.2\%.},
DOI = {10.1016/j.compag.2022.106731},
EarlyAccessDate = {JAN 2022},
Article-Number = {106731},
ISSN = {0168-1699},
EISSN = {1872-7107},
ResearcherID-Numbers = {Qureshi, Waqar/ABG-1744-2020
   Jabbar, Hamid/I-4879-2015
   Alanazi, Eisa/Y-9260-2019
   Rashid, Nasir/AAI-5424-2021
   Zeb, Ayesha/HPF-3047-2023
   },
ORCID-Numbers = {Qureshi, Waqar Shahid/0000-0003-0176-8145},
Unique-ID = {WOS:000754268300001},
}

@article{ WOS:001227288600001,
Author = {Sun, Yifei and Hao, Zhenbang and Chang, Hongcai and Yang, Jialin and
   Ding, Guiling and Guo, Zhanbao and He, Xi and Huang, Jiaxing},
Title = {Accurate mapping of rapeseed fields in the initial flowering stage using
   Sentinel-2 satellite images and convolutional neural networks},
Journal = {ECOLOGICAL INDICATORS},
Year = {2024},
Volume = {162},
Month = {MAY},
Abstract = {In high-intensity farming, swiftly and accurately adjusting the
   proportion of artificially reared pollinators according to the flowering
   phenology of crops is vital. This adjustment is essential for sustaining
   crop yields without disrupting the ecological niche of native
   pollinators. Although advancements in remote sensing provide practical
   means to gather data on crop coverage and extent, identifying
   insect-pollinated crops during their initial flowering to guide the
   deployment of managed pollinators is an underexamined research area.
   Here, we tested the capability of utilizing Sentinel-2 satellite images
   combined with a deep learning model to map crop fields during the
   initial flowering stage of insect-pollinated crops in Zhaosu County,
   Xinjiang, China. Specifically, we examined rapeseed fields by employing
   12 neural network designs to identify images of the initial flowering
   stage. Different network combinations of three convolutional neural
   network (CNN) models (U-Net, PSPNet, and DeepLab V3) and four different
   backbone networks (ResNet-18, ResNet-34, ResNet-50, and ResNet-101) were
   explored to determine the most effective model for detecting rapeseed
   fields at the initial flowering stage. A comparison was conducted with
   Sentinel-2 images obtained at the peak stage of rapeseed flowering. Our
   results suggest that the use of a deep learning model in combination
   with Sentinel-2 image data can successfully identify rapeseed fields at
   the initial flowering stage, thereby offering preliminary insights for
   the strategic introduction of managed pollinators. The PSPNet model
   emerged as the superior choice for the identification of rapeseed
   fields, exhibiting high accuracy in both detection and boundary
   recognition, with F1 scores of 88.17 \% and an intersection over union
   (IoU) of 53.11 \% during initial flowering and F1 scores of 93.33 \%
   with an IoU of 53.49 \% during peak flowering. The planting area of
   rapeseed fields detected by the model in Zhaosu County was 122.16 km2,
   distributed within an area of 1068 km2. These findings can provide
   foundational data for informed decisions regarding artificial pollinator
   supplementation, helping to sustain the health and stability of
   agricultural ecosystems.},
DOI = {10.1016/j.ecolind.2024.112027},
EarlyAccessDate = {APR 2024},
Article-Number = {112027},
ISSN = {1470-160X},
EISSN = {1872-7034},
ResearcherID-Numbers = {ding, guiling/JNE-5601-2023},
Unique-ID = {WOS:001227288600001},
}

@article{ WOS:001418455800001,
Author = {Li, Man and Wang, Renru and Dai, Ana and Yuan, Weitao and Yang, Guangbin
   and Xie, Lijun and Zhao, Weili and Zhao, Linglin},
Title = {Cascade DeepLab Net: A Method for Accurate Extraction of Fragmented
   Cultivated Land in Mountainous Areas Based on a Cascaded Network},
Journal = {AGRICULTURE-BASEL},
Year = {2025},
Volume = {15},
Number = {3},
Month = {FEB},
Abstract = {Approximately 24\% of the global land area consists of mountainous
   regions, with 10\% of the population relying on these areas for their
   cultivated land. Accurate statistics and monitoring of cultivated land
   in mountainous regions are crucial for ensuring food security, creating
   scientific land use policies, and protecting the ecological environment.
   However, the fragmented nature of cultivated land in these complex
   terrains challenges the effectiveness of existing extraction methods. To
   address this issue, this study proposed a cascaded network based on an
   improved semantic segmentation model (DeepLabV3+), called Cascade
   DeepLab Net, specifically designed to improve the accuracy in the
   scenario of fragmented land features. This method aims to accurately
   extract cultivated land from remote sensing images. This model enhances
   the accuracy of cultivated land extraction in complex terrains by
   incorporating the Style-based Recalibration Module (SRM), Spatial
   Attention Module (SAM), and Refinement Module (RM). The experimental
   results using high-resolution satellite images of mountainous areas in
   southern China show that the improved model achieved an overall accuracy
   (OA) of 92.33\% and an Intersection over Union (IoU) of 82.51\%, marking
   a significant improvement over models such as U-shaped Network (UNet),
   Pyramid Scene Parsing Network (PSPNet), and DeepLabV3+. This method
   enhances the efficiency and accuracy of monitoring cultivated land in
   mountainous areas and offers a scientific basis for policy formulation
   and resource management, aiding in ecological protection and sustainable
   development. Additionally, this study presents new ideas and methods for
   future applications of cultivated land monitoring in other complex
   terrain regions.},
DOI = {10.3390/agriculture15030348},
Article-Number = {348},
EISSN = {2077-0472},
ResearcherID-Numbers = {赵, 卫立/JXX-3838-2024
   Yuan, Weitao/AAV-6513-2020
   },
ORCID-Numbers = {Li, Man/0009-0008-6716-1091},
Unique-ID = {WOS:001418455800001},
}
