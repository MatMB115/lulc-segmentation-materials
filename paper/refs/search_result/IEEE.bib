@INPROCEEDINGS{10475229,
  author={Yele, Vijaykumar P. and Sedamkar, R.R. and Alegavi, Sujata},
  booktitle={2024 20th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP)}, 
  title={Systematic Analysis of Effective Segmentation and Classification for Land Use Land Cover in Hyperspectral Image using Deep Learning Methods: A Review of the State of the Art : Reviewing Deep Learning Techniques for Land Use and Cover in Hyperspectral Images}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This review paper delves into the intricate realm of segmenting and classifying Hyperspectral Images (HSI), complex visuals spanning numerous electromagnetic spectrum bands. HSI, garnering significant research attention, holds pivotal roles in geospatial applications, notably Land Use/Land Cover (LULC) mapping, demanding precise object identification. Addressing challenges posed by imbalanced data and limited labelled examples, the survey scrutinizes how researchers navigate HSI segmentation and classification. Briefly touching upon the foundational background of these techniques, the study navigates through diverse processing methods—thresholding, clustering, watershed, Deep Learning (DL) and others. Systematically exploring literature trends, DL advancements, attention mechanisms, data types, achieved accuracies and existing weaknesses, it strives to guide future research. Critically evaluating current knowledge, the paper illuminates’ gaps in HSI segmentation and classification, culminating in discussions on pertinent issues and prospective projects in this domain. Ultimately, this work aims to propel advancements by addressing knowledge lacunae and charting potential pathways for upcoming research initiatives.},
  keywords={Deep learning;Surveys;Image segmentation;Visualization;Systematics;Reviews;Navigation;Land Use Land Cover;Classification and Segmentation;Hyper Spectral Images;Deep Learning;Unbalanced data},
  doi={10.1109/AISP61396.2024.10475229},
  ISSN={2640-5768},
  month={Feb},}@INPROCEEDINGS{10220818,
  author={Gokarn, Aryaman and Patni, Khushi and Kulkarni, Sukanya},
  booktitle={2023 5th International Conference on Inventive Research in Computing Applications (ICIRCA)}, 
  title={Semantic Segmentation for Land Cover Using Bhuvan 2D Satellite Images}, 
  year={2023},
  volume={},
  number={},
  pages={1852-1857},
  abstract={This research study presents a a novel approach for semantic segmentation of land cover using Bhuvan 2D satellite images. The proposed approach utilizes U-Net models for classification. The dataset consists of 2D satellite images covering a region in India. A pre-processing pipeline is applied to extract relevant features and generate ground-truth labels. The model is trained on the dataset, and the results demonstrate its effectiveness in accurately classifying different types of land cover, such as forest, water bodies, agriculture, roads and urban areas, using performance metrics such as Dice coefficient (F1-Score), and Intersection over Union (IoU). The model is made more accurate and robust through the implementation of data augmentation techniques. The proposed approach can have significant applications in environmental monitoring, disaster management, and urban planning, providing accurate and detailed information on land cover patterns and changes over time.},
  keywords={Training;Semantic segmentation;Roads;Urban planning;Semantics;Pipelines;Feature extraction;Semantic Segmentation;Land cover Classification;Machine Learning;Deep Learning},
  doi={10.1109/ICIRCA57980.2023.10220818},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9172915,
  author={Huang, Yun and Tang, Linbo and Jing, Donglin and Li, Zhen and Tian, Yibing and Zhou, Shichao},
  booktitle={2019 IEEE International Conference on Signal, Information and Data Processing (ICSIDP)}, 
  title={Research on Crop Planting Area Classification From Remote Sensing Image Based on Deep Learning}, 
  year={2019},
  volume={},
  number={},
  pages={1-4},
  abstract={Remote sensing technology is widely used in agriculture monitoring because of the advantages of large-area simultaneous observation, low cost and dynamic monitoring of time and space. However, a manual visual interpretation method is often used to extract the information behind the remote sensing images, which is time and labor consuming. Moreover, handcraft features such as texture and structure of crop images are applied to classify crop planting area while these features are not robust. In order to reduce the cost and enhance the classification accuracy, we improved the state-of-the-art image semantic segmentation network SegNet in crop planting area classification which can speed up the convergence and reduce the model size largely with small gains in accuracy. The experiment result shows that the classification accuracy of the improved SegNet is slightly increased compared with SegNet, and the computational cost (FLOPs) of the improved SegNet is much less than SegNet.},
  keywords={crop classification;deep learning;remote sensing;agricultural monitoring},
  doi={10.1109/ICSIDP47821.2019.9172915},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9441483,
  author={Khan, Asim Hameed and Fraz, Muhammad Moazam and Shahzad, Muhammad},
  booktitle={2021 International Conference on Digital Futures and Transformative Technologies (ICoDT2)}, 
  title={Deep Learning Based Land Cover and Crop Type Classification: A Comparative Study}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Remote sensing data is available free of cost with an ever-increase in the number of satellites. This satellite imagery can be used as raw input from which cultivated/non-cultivated and crop fields can be mapped. Previous trends included the use of traditional ML techniques and standard CNN, RNN for such mappings. In this paper, we investigate the segmentation models for the task of Landcover and Crop type Classification. We investigate the UNet, SegNet, and DeepLabv3+ in the data-rich states of Nebraska, Mid-West, United States. We acquire dataset from Cropland data Layer provided by USDA National Agricultural Statistics Service. Our Experimental results show that cultivated and non-cultivated landcover is classified with an accuracy of 90% and crop types are classified around 70% ensuring the models trained on one geographical area can be used for accurate classification in other geographical areas, which makes it more reliable for real-time application in agricultural business. [GitHub].},
  keywords={Training;Image segmentation;Satellites;Agriculture;Sensors;Reliability;Task analysis;semantic segmentation;remote sensing;satellite imagery;convolutional neural networks;deep Learning;machine learning;landsat8;crop land data layer;classification},
  doi={10.1109/ICoDT252288.2021.9441483},
  ISSN={},
  month={May},}@ARTICLE{10197441,
  author={Zhang, Wei and Guo, Shanchuan and Zhang, Peng and Xia, Zilong and Zhang, Xingang and Lin, Cong and Tang, Pengfei and Fang, Hong and Du, Peijun},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={A Novel Knowledge-Driven Automated Solution for High-Resolution Cropland Extraction by Cross-Scale Sample Transfer}, 
  year={2023},
  volume={61},
  number={},
  pages={1-16},
  abstract={Accurate cropland mapping is significant for food security and sustainable development. The existing cropland map based on remote sensing mainly focuses on moderate to coarse spatial resolution, and these products are generally unsuitable for precision agriculture due to the lack of spatial details. Therefore, there is an urgent need to produce high-resolution (HR) cropland maps to meet current application demands. Recently, the typical classification workflow of HR images employs deep learning models combined with manually annotated samples, and visual interpretation of samples is usually labor-intensive and time-consuming, which is not conducive to large-scale applications. To address this problem, this article proposes an automated HR cropland extraction solution, namely, refinement–reclassification–extraction (RRE), including 1) refinement of 10-m spatial resolution cropland products; 2) reclassifying cropland using the refined product as a sample source; and 3) extracting HR cropland via designed cross-scale sample transfer. The strength of the proposed framework is that it leverages the existing moderate-resolution public products as prior knowledge and provides cross-scale transferable samples for HR images. The whole process does not require manual labeling of samples and is highly automated. Specifically, the experimental results in the three main grain production regions show that the RRE framework effectively reduces the interference of road networks and ridges, and F1 scores of extracted 1-m HR cropland reaches 87.71%–94.16%, which is comparable to the fully supervised (FS) cropland extraction method. In addition, the 10-m reclassified cropland, produced by the intermediate process of the RRE, outperforms current cropland product of Environmental Systems Research Institute, Inc. (ESRI) Land Cover and European Space Agency (ESA) World Cover.},
  keywords={Spatial resolution;Remote sensing;Data mining;Agriculture;Crops;Feature extraction;Time series analysis;Automated extraction;cropland;cross-scale sample transfer;high-resolution (HR) remote sensing image;prior knowledge},
  doi={10.1109/TGRS.2023.3299956},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10378824,
  author={Zamanoglu, Esref Samil and Erbay, Sergen and Cengil, Emine and Kosunalp, Selahattin and Tumen, Vedat and Demir, Kubilay},
  booktitle={2023 4th International Conference on Communications, Information, Electronic and Energy Systems (CIEES)}, 
  title={Land Cover Segmentation using DeepLabV3 and ResNet50}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Land cover segmentation has a great importance in various fields, including remote sensing, environmental monitoring, urban planning, agriculture, and natural resource management. It involves a division process of a landscape or region into different classes or categories with respect to the type of land cover in each place. With the recent developments in remote sensing area, high-resolution satellite images can be simply acquired. For an efficient land cover segmentation, in this study, a hybrid approach using deep learning architectures DeepLabV3 and ResNet34 is proposed. The proposed method has been trained and tested using the LandCover AI dataset. As a result, 88.2% F1-score value was obtained with the proposed hybrid approach.},
  keywords={Natural resources;Measurement;Urban planning;Semantics;Feature extraction;Satellite images;Task analysis;semantic segmentation;artificial intelligence;DeepLabV3;ResNet34;LandCoverAI},
  doi={10.1109/CIEES58940.2023.10378824},
  ISSN={},
  month={Nov},}@ARTICLE{10707292,
  author={Hu, Hua and Fu, Xueliang and Li, Chao and Liu, Min and Feng, Xiaolong},
  journal={IEEE Access}, 
  title={AMFF-LWBENet: A Novel Deep Learning Network Model for Extracting Lake Water Bodies From Remote Sensing Images}, 
  year={2024},
  volume={12},
  number={},
  pages={149001-149017},
  abstract={The extraction of lake water bodies from remote sensing images is vital for water resource management, environmental protection, climate change research, disaster monitoring, and land use planning. This study presents a novel model, AMFF-LWBENet (A Lake Water Body Extraction Network based on ASPP and Multi-scale Feature Fusion), designed to tackle challenges such as insufficient spatial detail, poor edge recognition, and low anti-noise performance found in existing lake water body extraction models. The model utilizes an encoder-decoder architecture, leveraging ResNet50 for downsampling to extract deep features, which are then fused more effectively through the multi-scale dense fusion (MDF) module, incorporating depthwise separable convolution and ASPP to enhance the integration of multi-scale features. Additionally, position and channel correlations in the feature map are captured using DANet, minimizing noise interference at the lake edge and improving segmentation accuracy. Bilinear interpolation is employed to upsample the feature map, and feature fusion is achieved through the cross-layer feature fusion (CFF) module, enabling precise lake water body extraction. The datasets utilized include a self-built W-H dataset, derived from Landsat images collected between 2015 and 2023, as well as the publicly available TP dataset. The AMFF-LWBENet achieved MIoU values of 97.52% on the W-H dataset and 97.5% on the TP dataset, surpassing current state-of-the-art semantic segmentation networks. These results suggest that AMFF-LWBENet is even more effective than many other networks in extracting lake water bodies, offering significantly enhanced support for a wide range of environmental and urban planning applications.},
  keywords={Remote sensing;Climate change;Water resources;Deep architecture;Semantic segmentation;Attention mechanisms;Water monitoring;Feature extraction;Residual neural networks;Urban planning;Risk management;Encoding;Decoding;Data models;Remote sensing;water body extraction;deep learning;semantic segmentation;attention mechanism;ResNet},
  doi={10.1109/ACCESS.2024.3476420},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8909243,
  author={Gargiulo, Massimiliano and Dell’Aglio, Domenico A. G. and Iodice, Antonio and Riccio, Daniele and Ruello, Giuseppe},
  booktitle={2019 IEEE International Workshop on Metrology for Agriculture and Forestry (MetroAgriFor)}, 
  title={Semantic Segmentation using Deep Learning: A case of study in Albufera Park, Valencia}, 
  year={2019},
  volume={},
  number={},
  pages={134-138},
  abstract={In this work, we explore the potential of using Sentinel-1 (S1) dual-polarization Synthetic Aperture Radar (SAR) data to obtain semantic maps that may complement those provided by the Level-2A (L2A) product of Sentinel-2 (S2). Specifically, we consider the use of the Interferometric Wide swath mode (IW) Sentinel-1 (S1) data collected along ascending/descending orbit, for wetlands and rice growing monitoring over the Natural Park of Albufera, Valencia. For this purpose, supervised Deep Learning (DL) approaches have been proposed to classify the pixels of the interested area. The advantages and disadvantages of different input stacks have been analysed, and the results have been assessed in terms of Accuracy, F1-score, Precision, and Recall. The results demonstrate that dual polarimetric Sentinel-1 SAR data can be effectively integrated in land cover maps produced by Sentinel-2 multispectral data. This approach is particularly helpful for rapid vegetation dynamics in tropical weather countries.},
  keywords={Training;Monitoring;Synthetic aperture radar;Adaptive optics;Optical polarization;Measurement;Semantics;deep learning;Sentinel-1;Sentinel-2;U-Net;semantic segmentation},
  doi={10.1109/MetroAgriFor.2019.8909243},
  ISSN={},
  month={Oct},}@ARTICLE{10070846,
  author={Zhang, Peng and Guo, Shanchuan and Zhang, Wei and Lin, Cong and Xia, Zilong and Zhang, Xingang and Fang, Hong and Du, Peijun},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Pixel–Scene–Pixel–Object Sample Transferring: A Labor-Free Approach for High-Resolution Plastic Greenhouse Mapping}, 
  year={2023},
  volume={61},
  number={},
  pages={1-17},
  abstract={As an important agriculture technique, plastic greenhouse (PG) has been widely used to increase crop yield and improve food security status in the world. The high-resolution spatial information of PG is of great significance to precise agricultural management and quantitative environmental assessment. Many studies have examined the role that remote sensing (RS) technology could play in mapping and monitoring PG coverage. However, these methods, which employ either the traditional machine learning algorithms or the deep learning models, depend on massive manually labeled samples. To address this problem, this article proposes a new cross-scale sample transferring method to generate high-resolution samples for automated PG mapping. The proposed method aims to transfer reliable label information from Sentinel-2 images (10 m) to high-resolution images (0.2 m) in a pixel–scene–pixel–object (PSPO) transferring process. In the proposed PG mapping workflow, the low-resolution label information of PG/non-PG can be obtained from an advanced plastic greenhouse index (APGI) which is calculated in Sentinel-2 images, and then, the label information is transferred to the corresponding high-resolution images using the proposed PSPO transferring method. Finally, the transferred high-resolution samples are used to train the deep semantic segmentation model and produce PG mapping results. The whole process is labor-free which requires no manually labeled samples. The experimental results on three collected datasets show that the proposed approach can automatically generate accurate and reliable high-resolution samples, and the final PG mapping results can achieve an overall accuracy (OA) of 89.52%–97.65% and F1 score of 84.13%–94.03%, which is comparable to the fully supervised semantic segmentation model.},
  keywords={Human-robot interaction;Magnetic resonance imaging;Cams;Semantic segmentation;Plastics;Green products;Remote sensing;Advanced plastic greenhouse index (APGI);cross-scale sample transferring;high-resolution imagery (HRI);plastic greenhouse (PG) mapping;weakly supervised semantic segmentation (WSSS)},
  doi={10.1109/TGRS.2023.3257293},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{10356532,
  author={Hu, Haiyang and Yang, Linnan and Chen, Jiaojiao and Luo, Shuang},
  booktitle={2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={The remote sensing image segmentation of land cover based on multi-scale attention features}, 
  year={2023},
  volume={},
  number={},
  pages={429-436},
  abstract={Segmentation of land cover in remote sensing images is a task that involves interpreting remote sensing data using machine vision. Satisfying segmentation results in agriculture and forestry regions can guide land resource management, natural environment protection, urban construction, and the distribution of agricultural products. However, the performance of the widely used deep learning segmentation model on high-resolution remote sensing segmentation datasets in agriculture and forestry regions needs to be improved. To solve the problems of poor accuracy and loss of context information in remote sensing image semantic segmentation, this paper proposes an improved semantic segmentation network architecture. The model utilizes multi-scale feature extraction, deploys a multi-layer attention feature fusion module and an up-sampling fusion module to capture high-quality multi-scale context information, correctly handle scale changes, and help narrow the semantic gap between different levels. Finally, the proposed MLP decoder refers to the dynamic up-sampling operator to aggregate the information at different levels to achieve pixel segmentation. To verify the effectiveness of our proposed model, the researchers conducted experiments on two land cover segmentation datasets. The training process specifically designs data augmentation strategies for remote sensing segmentation tasks to enhance the model’s generalization ability. The final model achieved an mIoU (mean Intersection over Union) of 65.05% on the self-built rural land cover datasets, surpassing the benchmark network UPerNet by 5.92%. On the LoveDA dataset, our model achieved state-of-the-art performance with an mIoU of 53.39%, demonstrating its versatility.},
  keywords={Training;Semantic segmentation;Semantics;Object segmentation;Forestry;Feature extraction;Decoding;land cover;remote sensing image;neural network;attention mechanism;multi-scale feature},
  doi={10.1109/ICTAI59109.2023.00069},
  ISSN={2375-0197},
  month={Nov},}@INPROCEEDINGS{10337565,
  author={Salah, Khawla Ben and Othmani, Mohamed and Saida, Selma and Kherallah, Monji},
  booktitle={2023 International Conference on Cyberworlds (CW)}, 
  title={Improved approach for Semantic Segmentation of MBRSC aerial Imagery based on Transfer Learning and modified UNet}, 
  year={2023},
  volume={},
  number={},
  pages={46-53},
  abstract={Aerial imagery has emerged in numerous fields such as sustainable development, forestry, urban planning, agriculture, earth science and climate research. Extracting relevant information from satellite images, such as building detection, road extraction, and land cover classification, is crucial for decision-making. Semantic segmentation (SS),generates a dense pixel-wise segmentation map of a given satellite image where each pixel is related necessarily to a specific class. (SS) has become essential to reach the aforementioned goals. In this context, we presented an improved approach for semantic segmentation of aerial images using the pre-trained CNN VGG16 model and the modified U-Net architecture. Our results show that our proposed approach exceeds state of the art methods in accurately classifying land cover types in terms of dice coefficient and an average accuracy of 82.30% of 87.81% respectively.},
  keywords={Training;Semantic segmentation;Computational modeling;Urban planning;Transfer learning;Computer architecture;Satellite images;Semantic segmentation;modified UNet decoder;VGG16;aerial images},
  doi={10.1109/CW58918.2023.00017},
  ISSN={2642-3596},
  month={Oct},}@INPROCEEDINGS{9323603,
  author={de Albuquerque, Anesmar Olino and de Bem, Pablo Pozzobon and dos Santos de Moura, Rebeca and de Carvalho, Osmar Luiz Ferreira and Ferreira, Pedro Henrique Guimarães and Silva, Cristiano Rosa and Gomes, Roberto Arnaldo Trancoso and Guimarães, Renato Fontes and de Carvalho, Osmar Abílio},
  booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={Center Pivot Classification with Deep Residual U-NET}, 
  year={2020},
  volume={},
  number={},
  pages={1596-1599},
  abstract={Center pivots are a modern irrigation technique mainly applied in precision agriculture, once it has high efficiency in water consumption and low labor workers when compared to traditional irrigation methods. Knowing their location is valuable since monitoring, evaluating, and estimating essential features in the lands becomes easier, remote sensing is a robust tool to act upon this kind of problem. To identify center pivots, we used a deep residual U-Net with a pixel comparison at image reconstruction to enhance results. We obtained a validation loss of 0.19, which adds up with pixel comparison. Results were satisfactory, with 2070 correct identifications from a total of 2109 center pivots (98.15%). Future studies to improve these results would require more data in different places and seasons.},
  keywords={Remote sensing;Irrigation;Training;Earth;Artificial satellites;Image segmentation;Satellites;Center pivot;deep learning;deep residual u-net;remote sensing},
  doi={10.1109/IGARSS39084.2020.9323603},
  ISSN={2153-7003},
  month={Sep.},}@INPROCEEDINGS{10283308,
  author={Le, Minh Tri and Wessels, Konrad and Caraballo-Vega, Jordan and Thomas, Nathan and Wooten, Margaret and Carroll, Mark and Neigh, Christopher},
  booktitle={IGARSS 2023 - 2023 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={Training Strategies of Cnn for Land Cover Mapping with High Resolution Multi-Spectral Imagery in Senegal}, 
  year={2023},
  volume={},
  number={},
  pages={6358-6361},
  abstract={Land cover mapping has been a valuable tool in capturing changes in many developing regions in Africa. Senegal has been a hotspot of change where agricultural activity has rapidly increased. Agriculture in this region is often a complex mosaic of small fields which makes them difficult to classify using conventional land cover mapping methods and coarse-resolution satellite imagery. WorldView (WV) satellites provide very high-resolution imagery that is ideal for semantic segmentation using convolutional neural networks (CNN). In this study, we introduced training strategies that scale up the training data for the U-Net model using 2 m WV-2 and 3 imagery to overcome the challenges of regional mapping with a patchwork of hundreds of images. The proposed strategies increased the number of training data for the U-Net model in three main scenarios, (i) conventional training, (ii) model transfer, and (iii) transfer learning, and we evaluated model generalizability on test sets for two different regions in Senegal. The results showed that models rapidly reached a high level of performance with a limited increase in additional training in conventional and transfer learning strategies. In these two strategies, the U-Net consistently produced >87% average accuracy for trained images and >70% average accuracy for all test images at the final scale level. The research opens opportunities to produce regional land cover maps in West Africa without generating a prohibitively large amount of training data.},
  keywords={Training;Satellites;Semantic segmentation;Scalability;Transfer learning;Training data;Africa;WorldView;Senegal;CNN;segmentation;land cover},
  doi={10.1109/IGARSS52108.2023.10283308},
  ISSN={2153-7003},
  month={July},}@ARTICLE{9566776,
  author={Gbodjo, Yawogan Jean Eudes and Montet, Olivier and Ienco, Dino and Gaetano, Raffaele and Dupuy, Stephane},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={Multisensor Land Cover Classification With Sparsely Annotated Data Based on Convolutional Neural Networks and Self-Distillation}, 
  year={2021},
  volume={14},
  number={},
  pages={11485-11499},
  abstract={Extensive research studies have been conducted in recent years to exploit the complementarity among multisensor (or multimodal) remote sensing data for prominent applications such as land cover mapping. In order to make a step further with respect to previous studies, which investigate multitemporal SAR and optical data or multitemporal/multiscale optical combinations, here, we propose a deep learning framework that simultaneously integrates all these input sources, specifically multitemporal SAR/optical data and fine-scale optical information at their native temporal and spatial resolutions. Our proposal relies on a patch-based multibranch convolutional neural network (CNN) that exploits different per-source encoders to deal with the specificity of the input signals. In addition, we introduce a new self-distillation strategy to boost the per-source analyses and exploit the interplay among the different input sources. This new strategy leverages the final prediction of the multisource framework to guide the learning of the per-source CNN encoders supporting the network to learn from itself. Experiments are carried out on two real-world benchmarks, namely, the Reunion island (a French overseas department) and the Dordogne study site (a southwest department in France), where the annotated reference data were collected under operational constraints (sparsely annotated ground-truth data). Obtained results providing an overall classification accuracy of about 94% (respectively, 88%) on the Reunion island (respectively, the Dordogne) study site highlight the effectiveness of our framework based on CNNs and self-distillation to combine heterogeneous multisensor remote sensing data and confirm the benefit of multimodal analysis for downstream tasks such as land cover mapping.},
  keywords={Optical sensors;Optical imaging;Remote sensing;Spatial resolution;Synthetic aperture radar;Convolutional neural networks;Optical computing;Convolutional neural networks (CNNs);land use and land cover (LULC) mapping;multisensor;multitemporal and multiscale remote sensing;self-distillation;sparsely annotated data},
  doi={10.1109/JSTARS.2021.3119191},
  ISSN={2151-1535},
  month={},}@ARTICLE{9224624,
  author={De Oliveira, Joel Parente and Costa, Marly Guimarães Fernandes and Filho, Cícero},
  journal={IEEE Access}, 
  title={Methodology of Data Fusion Using Deep Learning for Semantic Segmentation of Land Types in the Amazon}, 
  year={2020},
  volume={8},
  number={},
  pages={187864-187875},
  abstract={This study proposes a methodology using deep learning and a multi-resolution segmentation algorithm to perform the semantic segmentation of remote sensing images. Initially the image is segmented using a CNN, and then an image with homogeneous regions is generated using a multi-resolution segmentation algorithm. Finally, a data fusion process is performed with these two images, generating the final classified image. The field of study was the Brazilian Amazon region. The proposed methodology classifies images in the following classes: forest, pasture and agriculture. The input data used were LANDSAT-8/OLI images. The reference data were extracted from the results of the TerraClass project in 2014. Two datasets were evaluated: the first with six bands and the second with three bands. Three CNN architectures were evaluated together with three optimization methods: SGDM, ADAM, and RMSProp and the dropout and L2 regularization methods as methods for generalization improvement. The best model, CNN + optimization method + technique for generalization improvement, evaluated in the validation set, was submitted to a 5-fold cross validation methodology, and the results were compared with pre-trained networks using the learning transfer methodology; in this case the networks used for comparison were ResNet50, InceptionResnetv2, MobileNetv2 and Xception. The proposed methodology was evaluated through image segmentation of some regions of the Amazon. Finally, the proposed methodology was evaluated in regions used by other authors. The accuracy values obtained for the images evaluated were over 99%.},
  keywords={Remote sensing;Artificial satellites;Earth;Image segmentation;Deep learning;Forestry;Agriculture;Deep learning;convolutional neural networks;remote sensing;image segmentation},
  doi={10.1109/ACCESS.2020.3031533},
  ISSN={2169-3536},
  month={},}@ARTICLE{10843732,
  author={Zhang, Jing and Wu, Tianjun and Luo, Jiancheng and Hu, Xiaodong and Wang, Lingyu and Li, Manjia and Lu, Xuanzhi and Li, Ziqi},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Toward Agricultural Cultivation Parcels Extraction in the Complex Mountainous Areas Using Prior Information and Deep Learning}, 
  year={2025},
  volume={63},
  number={},
  pages={1-14},
  abstract={Accurately determining the spatial position and distribution structure of agricultural cultivation parcels (ACPs) is essential for regional agricultural planning and food security. Currently, utilizing deep learning technology based on very high resolution remote sensing imagery has proven effective for intelligent parcel extraction. However, relying solely on the model output, especially from single-task models in mountainous regions with complex, heterogeneous, and fragmented smallholder agriculture, remains questionable. To address this challenge, leveraging geographical prior knowledge is critical. This article proposes using the deep semantic segmentation algorithm in conjunction with comprehensive prior strategies. An improved densely connected link network (D-LinkNet) is employed to delineate the parcels, while geographical zoning, coarse spatial scope, stratification strategy, and homogeneity checking are exerted to understand regions, facilitate samples, reduce interferences, decompose objects, and identify undersegmentation. The proposed framework was validated in Jiangjin district, Chongqing of China, using Gaofen-2 images as the vital data. Compared to the method relying solely on deep learning, our method achieved superior performance with an overall accuracy of 0.924, Kappa coefficient of 0.847,  $F1$  score of 0.921, and IoU exceeding 0.8. Moreover, the results demonstrated high accuracy in the individual geometric precision of parcel. Over 1.23 million parcels were identified, comprising 77% cultivated land and 23% garden land. The areal proportion of paddy fields, drylands, and pepper gardens approximated 1:1:1, consistent with statistical data. This method offers a feasible approach for finely extracting agricultural parcels.},
  keywords={Feature extraction;Remote sensing;Crops;Spatial resolution;Deep learning;Accuracy;Soil;Farming;Data mining;Surfaces;Agricultural cultivation parcels (ACPs);complex mountainous areas;deep learning;geographical zoning;stratification strategy},
  doi={10.1109/TGRS.2025.3530615},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{8899234,
  author={Pourmohammadi, Pariya and Adjeroh, Donald and Strager, Michael P.},
  booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={Predicting Impervious Land Expansion Using Deep Deconvolutional Neural Networks}, 
  year={2019},
  volume={},
  number={},
  pages={9855-9858},
  abstract={In this research, we propose a method for modeling land change using the idea of pixel-wise semantic segmentation through deep deconvolutional neural networks. This analysis is done on a watershed scale with a focus on where developed lands are predicted to expand. The novelty of our approach is in the application of deep learning in the prediction of land transformation, where we integrate high dimensional feature classes encompassing multiple variables. We introduce a method to construct cubes of land patches which include information related to the characteristics of terrain, proximity to other features, population, geo-political-boundaries, and public policy. After modeling the development expansion in a watershed using an encoder-decoder network, the accuracy of the model is computed through the Area Under the Curve of Receiver Operating Characteristics (AUC-ROC). Model performance indicates an accuracy of 80%. Future modeling should consider the use of this technique to better understand and map the spatially explicit landscape changes and aid in land use decision making.},
  keywords={Pixel-wise Segmentation;Land Change Prediction;Deconvolutional Neural Networks},
  doi={10.1109/IGARSS.2019.8899234},
  ISSN={2153-7003},
  month={July},}@ARTICLE{8700168,
  author={Wu, Ming and Zhang, Chuang and Liu, Jiaming and Zhou, Lichen and Li, Xiaoqi},
  journal={IEEE Access}, 
  title={Towards Accurate High Resolution Satellite Image Semantic Segmentation}, 
  year={2019},
  volume={7},
  number={},
  pages={55609-55619},
  abstract={Satellite image semantic segmentation, including extracting road, detecting building, and identifying land cover types, is essential for sustainable development, agriculture, forestry, urban planning, and climate change research. Nevertheless, it is still unclear how to develop a refined semantic segmentation model in an efficient and elegant way. In this paper, we propose attention dilation-LinkNet (AD-LinkNet) neural network that adopts encoder–decoder structure, serial–parallel combination dilated convolution, channel-wise attention mechanism, and pretrained encoder for semantic segmentation. Serial–parallel combination dilated convolution enlarges receptive field as well as assemble multi-scale features for multi-scale objects, such as long-span road and small pool. The channel-wise attention mechanism is designed to advantage the context information in the satellite image. The experimental results on road extraction and surface classification data sets prove that the AD-LinkNet shows a significant effect on improving the segmentation accuracy. We defeated the D-Linknet algorithm that won the first place in the CVPR 2018 DeepGlobe road extraction competition.},
  keywords={Image segmentation;Semantics;Satellites;Convolutional neural networks;Task analysis;Roads;Climate change;Satellite image;semantic segmentation;AD-LinkNet;dilated convolution;channel-wise attention},
  doi={10.1109/ACCESS.2019.2913442},
  ISSN={2169-3536},
  month={},}
