Scopus
EXPORT DATE: 07 May 2025

@ARTICLE{Panboonyuen2023,
	author = {Panboonyuen, Teerapong and Charoenphon, Chaiyut and Satirapod, Chalermchon},
	title = {MeViT: A Medium-Resolution Vision Transformer for Semantic Segmentation on Landsat Satellite Imagery for Agriculture in Thailand},
	year = {2023},
	journal = {Remote Sensing},
	volume = {15},
	number = {21},
	doi = {10.3390/rs15215124},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176372217&doi=10.3390%2frs15215124&partnerID=40&md5=728339ad3dcbdd9de54b2a25a1bde52b},
	abstract = {Semantic segmentation is a fundamental task in remote sensing image analysis that aims to classify each pixel in an image into different land use and land cover (LULC) segmentation tasks. In this paper, we propose MeViT (Medium-Resolution Vision Transformer) on Landsat satellite imagery for the main economic crops in Thailand as follows: (i) para rubber, (ii) corn, and (iii) pineapple. Therefore, our proposed MeViT enhances vision transformers (ViTs), one of the modern deep learning on computer vision tasks, to learn semantically rich and spatially precise multi-scale representations by integrating medium-resolution multi-branch architectures with ViTs. We revised mixed-scale convolutional feedforward networks (MixCFN) by incorporating multiple depth-wise convolution paths to extract multi-scale local information to balance the model’s performance and efficiency. To evaluate the effectiveness of our proposed method, we conduct extensive experiments on the publicly available dataset of Thailand scenes and compare the results with several state-of-the-art deep learning methods. The experimental results demonstrate that our proposed MeViT outperforms existing methods and performs better in the semantic segmentation of Thailand scenes. The evaluation metrics used are precision, recall, F1 score, and mean intersection over union (IoU). Among the models compared, MeViT, our proposed model, achieves the best performance in all evaluation metrics. MeViT achieves a precision of 92.22%, a recall of 94.69%, an F1 score of 93.44%, and a mean IoU of 83.63%. These results demonstrate the effectiveness of our proposed approach in accurately segmenting Thai Landsat-8 data. The achieved F1 score overall, using our proposed MeViT, is 93.44%, which is a major significance of this work. © 2023 by the authors.},
	author_keywords = {deep learning; Landsat; remote sensing imagery; semantic segmentation; transformer},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Shokati2025,
	author = {Shokati, Hadi and Engelhardt, Andreas and Seufferheld, Kay and Taghizadeh-Mehrjardi, Ruhollah and Fiener, Peter and Lensch, Hendrik P.A. and Scholten, Thomas},
	title = {Erosion-SAM: Semantic segmentation of soil erosion by water},
	year = {2025},
	journal = {Catena},
	volume = {254},
	doi = {10.1016/j.catena.2025.108954},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000558890&doi=10.1016%2fj.catena.2025.108954&partnerID=40&md5=8c159ed42f0cfcd71d6512ae78ab4884},
	abstract = {Soil erosion (SE) by water threatens global agriculture by depleting fertile topsoil and causing economic costs. Conventional SE models struggle to capture the complex, non-linear interactions between SE drivers. Recently, machine learning has gained attention for SE modeling. However, machine learning requires large data sets for effective training and validation. In this study, we present Erosion-SAM, which fine-tunes the Segment Anything Model (SAM) for automatic segmentation of water erosion features in high-resolution remote sensing imagery. The data set comprised 405 manually segmented agricultural fields from erosion-prone areas obtained from the rain gauge-adjusted radar rainfall data (RADOLAN) for bare cropland, vegetated cropland, and grassland. Three approaches were evaluated: two pre-processing techniques— resizing and cropping — and an improved version of the resizing approach with user-defined prompts during the testing phase. All fine-tuned models outperformed the original SAM, with the prompt-based resizing method showing the highest accuracy, especially for grassland (recall: 0.90, precision: 0.82, dice coefficient: 0.86, IoU: 0.75). SAM performed better than the cropping approach only on bare cropland. This discrepancy is attributed to the tendency of SAM to overestimate SE by classifying a large proportion of fields as eroded, which increases recall by covering most of the eroded pixels. All three fine-tuned approaches showed strong correlations with the actual SE severity ratios, with the prompt-enhanced resizing approach achieving the highest R2 of 0.93. In summary, Erosion-SAM shows promising potential for automatically detecting SE features from remote sensing images. The generated data sets can be applied to machine learning-based SE modeling, providing accurate and consistent training data across different land cover types, and offering a reliable alternative to traditional SE models. In addition, erosion-SAM can make a valuable contribution to the precise monitoring of SE with high temporal resolution over large areas, and its results could benefit reinsurance and insurance-related risk solutions. © 2025 The Author(s)},
	author_keywords = {Erosion monitoring; Fine-tuning; RADOLAN; SAM; Soil erosion; Transfer learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lin2024353,
	author = {Lin, Yunhao and Wang, Yanjun and Li, Shaochun and Cai, Hengfan},
	title = {A coupled DeepLab and Transformer approach for fine classification of crop cultivation types in remote sensing; [用于遥感作物种植类型精细分类的 DeepLab 和 Transformer 耦合方法]},
	year = {2024},
	journal = {Cehui Xuebao/Acta Geodaetica et Cartographica Sinica},
	volume = {53},
	number = {2},
	pages = {353 – 366},
	doi = {10.11947/j.AGCS.2024.20220692},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189854616&doi=10.11947%2fj.AGCS.2024.20220692&partnerID=40&md5=ba8a80933843159cfa87f01bac7883cf},
	abstract = {How to accurately monitor the planting of different types of complex farmland crops by remote sensing is the key to the realization of agricultural area survey and crop yield estimation in the area of smart rural agriculture. In the current pixel level semantic segmentation of crop planting in high-resolution images, the deep convolution neural network is difficult to take into account the spatial multi-scale global features and local details, which leads to problems such as blurring boundary contours between various farmland plots and low internal integrity of the same farmland area. In view of these shortcomings, this paper designs and proposes a dual branch parallel feature fusion network (FDTNet) that couples DeepLabv3 + and Transformer encoders to achieve fine remote sensing monitoring of crop planting. Firstly, DeepLabv3 + and Transformer are embedded in FDTNet in parallel to capture the local and global features of farmland image respectively. Secondly, the coupled attention fusion module (CAFM) is used to effectively fuse the characteristics of the two features. Then, in the decoder stage, the convolutional block attention module (CBAM) is applied to enhance the weight of the effective features of the convolutional layer. Finally, the progressive multi-level feature fusion strategy is adopted to fully fuse the effective features in the encoder and decoder, and output the feature map to achieve high-precision classification and recognition of late rice, middle rice, lotus root field, vegetable field and greenhouse. In order to verify the effectiveness of FDTNet network model in high-resolution crop classification application, this paper selects different high-resolution Yuhu dataset and Zhejiang dataset and experimental results of mloU reach 74.7% and 81.4 %, respectively. The mloU of FDTNet can be 2.2% and 3.6% respectively higher than the existing deep learning methods, such as UNet, DeepLabv3, DeepLabv3 +, ResT and Res-Swin. The results show that FDTNet has better classification performance than the compared methods in two types of farmland scenes, which have single texture and large sample size, or multiple texture and small sample size. The proposed FDTNet has a comprehensive ability to extract effective features of multiple category crops. © 2024 SinoMaps Press. All rights reserved.},
	author_keywords = {crop planting type; deep learning; feature fusion; high-resolution remote sensing image; semantic segmentation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Ayushi20243418,
	author = {Ayushi and Buttar, Preetpal Kaur},
	title = {Satellite Imagery Analysis for Crop Type Segmentation Using U-Net Architecture},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {235},
	pages = {3418 – 3427},
	doi = {10.1016/j.procs.2024.04.322},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196432324&doi=10.1016%2fj.procs.2024.04.322&partnerID=40&md5=c086c48c3b8af1fa1d867e48264e170f},
	abstract = {Analyzing satellite images plays a critical role in surveying and monitoring agricultural areas, enabling various applications such as precision agriculture, land use planning, and yield estimation. One of the crucial steps in these applications is accurate crop-type segmentation from satellite imagery. This task becomes challenging in the scenarios of smallholder farms due to their irregular field shapes, frequent cloud cover, small plot sizes, and a severe shortage of training data, which make it difficult to apply conventional machine learning methods effectively. In this research work, a technique for segmenting the crop types from the difficult scenario of smallholder farms based on fully convolutional encoder-decoder semantic segmentation architecture, U-Net, has been proposed and its performance has been compared with the traditional machine learning techniques. To evaluate the proposed approach, experimental assessments were conducted on the Kenya satellite imagery crop dataset. The proposed technique achieved an accuracy, precision, recall, and F1 score of 95.3%, 80.2%, 68.1%, and 73.6%, respectively. The results demonstrate that the U-Net model surpasses conventional image classification methods in accurately segmenting different crop types. © 2024 Elsevier B.V.. All rights reserved.},
	author_keywords = {agriculture; convolutional neural networks; crop type mapping; fully convolutional networks; satellite images; semantic image segmentation; Sentinel-2},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Kavipriya2025222,
	author = {Kavipriya, J. and Vadivu, G.},
	title = {Semantic Segmentation of Satellite Imagery Using Optimized U-Net Model},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2362},
	pages = {222 – 232},
	doi = {10.1007/978-3-031-82386-2_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219198749&doi=10.1007%2f978-3-031-82386-2_17&partnerID=40&md5=ba27c729a19bced5533304ef7836cd3c},
	abstract = {The classification of land cover is crucial due to increasing demands and population expansion. Segmentation of the terrain is utilized in environmental monitoring to accurately identify and delineate areas of agriculture, buildings, and water bodies. Satellite imagery is quite valuable for the purpose of segmentation. Deep learning models offer automated and precise segmentation of satellite imagery. The U-Net architecture is widely employed as an encoder-decoder structure for the purpose of segmenting medical and remote sensing images. This study investigates the process of dividing satellite images into segments using an optimized U-Net model. Our model utilizes improved equal weights to calculate loss functions. In addition, we have implemented a dropout layer for each convolutional block in order to decrease the computational time required for feature extraction in the encoder layer of the optimized U-Net model. Our study examines the Dubai dataset, which has six distinct classes. The optimized U-Net model we propose achieves an accuracy of 81.5% and Intersection over Union (IoU) values of 61.7% for segmenting the dataset. These metrics are acquired with a reduced number of epochs, hence decreasing the computational expense. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Artificial Intelligence; Deep Learning; modified U-Net; Satellite imagery; Segmentation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xu2022,
	author = {Xu, Lu and Ming, Dongping and Du, Tongyao and Chen, Yangyang and Dong, Dehui and Zhou, Chenghu},
	title = {Delineation of cultivated land parcels based on deep convolutional networks and geographical thematic scene division of remotely sensed images},
	year = {2022},
	journal = {Computers and Electronics in Agriculture},
	volume = {192},
	doi = {10.1016/j.compag.2021.106611},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120728116&doi=10.1016%2fj.compag.2021.106611&partnerID=40&md5=aa7f226a11eddf981aa0eac7c28cb511},
	abstract = {Extraction of cultivated land information from high spatial resolution remote sensing images is increasingly becoming an important approach to digitization and informatization in modern agriculture. The continuous development of deep learning technology has made it possible to extract information of cultivated land parcels by an intelligent way. Aiming at fine extraction of cultivated land parcels within large areas, this article builds a framework of geographical thematic scene division according to the rule of territorial differentiation in geography. A deep learning semantic segmentation network, improved U-net with depthwise separable convolution (DSCUnet), is proposed to achieve the division of the whole image. Then, an extended multichannel richer convolutional features (RCF) network is involved to delineate the boundaries of cultivated land parcels from agricultural functional scenes obtained by the former step. In order to testify the feasibility and effectiveness of the proposed methods, this article implemented experiments using Gaofen-2 images with different spatial resolution. The results show an outstanding performance using methods proposed in this article in both dividing agricultural functional scenes and delineating cultivated land parcels compared with other commonly used methods. Meanwhile, the extraction results have the highest accuracy in both the traditional evaluation indices (like Precision, Recall, F1, and IoU) and geometric boundary precision of cultivated land parcels. The methods in this article can provide a feasible solution to the problem of finely extracting cultivated land parcels information within large areas and complex landscape conditions in practical applications. © 2021 Elsevier B.V.},
	author_keywords = {Agricultural remote sensing; Cultivated land parcels; Deep learning; Geographical Thematic scenes; Semantic segmentation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 45}
}

@CONFERENCE{Basir2024173,
	author = {Basir, Syazwani and Abdul Aziz, Nurul Aina and Abiddin, Nurshafiza Zanal},
	title = {Semantic Segmentation of Paddy Parcels Using Deep Neural Networks Based on DeepLabV3},
	year = {2024},
	journal = {International Conference on Geographical Information Systems Theory, Applications and Management, GISTAM - Proceedings},
	pages = {173 – 180},
	doi = {10.5220/0012698200003696},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194144598&doi=10.5220%2f0012698200003696&partnerID=40&md5=4066113550416ba9f4d13530b9e2cef0},
	abstract = {Paddy parcels are frequently converted to other structures which contributes significantly to changes in paddy cultivation areas and a decrease in rice production. Determining the current land use status for paddy parcels annually is quite challenging; thus, the Paddy Geospatial Information System (MakGeoPadi) has been developed to determine the precise Malaysian paddy cultivation regions in order to provide a sufficient food supply for the entire country. Deep convolutional neural network (DCNN) algorithms such as DeepLabV3 are used in this study to accurately estimate paddy yield of 12 granaries. The objective of this study is to enhance the DeepLabV3 paddy parcel detection model to generate data that can be relied upon for reliable decision-making. Deep-learning applications based on the DeepLabV3 model were classified into four classes: active paddy parcel (PA), miscellaneous paddy parcel (PP), permanent structures (SK) and permanent crop (TK) using ResNet50 in ArcGIS Pro version 2.9. DCNN has been utilised to perform semantic segmentation. The DCNN architecture known as DeepLabV3 is trained using the 16,000 datasets in the experiment, with Pleiades satellite images scaled at 224 x 224-pixel sizes. Following the training phase, the DeepLabV3 model achieved the highest successful training accuracy, scoring 91.6%. © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Agriculture; ArcGIS Pro; DeepLabV3; Food Security; Paddy},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Spasev2024127,
	author = {Spasev, Vlatko and Dimitrovski, Ivica and Kitanovski, Ivan and Chorbev, Ivan},
	title = {Semantic Segmentation of Remote Sensing Images: Definition, Methods, Datasets and Applications},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {1991 CCIS},
	pages = {127 – 140},
	doi = {10.1007/978-3-031-54321-0_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187677196&doi=10.1007%2f978-3-031-54321-0_9&partnerID=40&md5=1f02e7bf2b6b9a2b1e788a7fd0ab121c},
	abstract = {Semantic segmentation of remote sensing images is a vital task in the field of remote sensing and computer vision. The goal is to produce a dense pixel-wise segmentation map of an image, where a specific class is assigned to each pixel, enabling detailed analysis and understanding of the Earth’s surface. This paper provides an overview of semantic segmentation in remote sensing, starting with a definition of the task and its significance in extracting valuable information from remote sensing imagery. Various methods used for semantic segmentation in remote sensing are discussed, including traditional approaches such as region-based and pixel-based methods, as well as more recent deep learning-based techniques. Next, the paper delves into the available datasets for semantic segmentation of remote sensing images. Many available datasets are reviewed, highlighting their characteristics, including the number of images, image size, number of labels, spatial resolution, format and spectral bands. These datasets serve as valuable resources for training, evaluating, and benchmarking semantic segmentation algorithms in remote sensing applications. Furthermore, the paper highlights the broad range of applications enabled by semantic segmentation in remote sensing, including urban planning, land cover mapping, disaster management, environmental monitoring, and precision agriculture. Overall, this paper serves as a comprehensive guide to semantic segmentation of remote sensing images, providing insights into its definition, methods, available datasets and wide-ranging applications. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Deep Learning; Earth Observation; Remote Sensing Images; Semantic Segmentation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Hu2023429,
	author = {Hu, Haiyang and Yang, Linnan and Chen, Jiaojiao and Luo, Shuang},
	title = {The remote sensing image segmentation of land cover based on multi-scale attention features},
	year = {2023},
	journal = {Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI},
	pages = {429 – 436},
	doi = {10.1109/ICTAI59109.2023.00069},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182395394&doi=10.1109%2fICTAI59109.2023.00069&partnerID=40&md5=660e756997749f89ebbd880bccd3215c},
	abstract = {Segmentation of land cover in remote sensing images is a task that involves interpreting remote sensing data using machine vision. Satisfying segmentation results in agriculture and forestry regions can guide land resource management, natural environment protection, urban construction, and the distribution of agricultural products. However, the performance of the widely used deep learning segmentation model on high-resolution remote sensing segmentation datasets in agriculture and forestry regions needs to be improved. To solve the problems of poor accuracy and loss of context information in remote sensing image semantic segmentation, this paper proposes an improved semantic segmentation network architecture. The model utilizes multi-scale feature extraction, deploys a multi-layer attention feature fusion module and an up-sampling fusion module to capture high-quality multi-scale context information, correctly handle scale changes, and help narrow the semantic gap between different levels. Finally, the proposed MLP decoder refers to the dynamic up-sampling operator to aggregate the information at different levels to achieve pixel segmentation. To verify the effectiveness of our proposed model, the researchers conducted experiments on two land cover segmentation datasets. The training process specifically designs data augmentation strategies for remote sensing segmentation tasks to enhance the model's generalization ability. The final model achieved an mIoU (mean Intersection over Union) of 65.05% on the self-built rural land cover datasets, surpassing the benchmark network UPerNet by 5.92%. On the LoveDA dataset, our model achieved state-of-the-art performance with an mIoU of 53.39%, demonstrating its versatility. © 2023 IEEE.},
	author_keywords = {attention mechanism; land cover; multi-scale feature; neural network; remote sensing image},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Habiboullah2022394,
	author = {Habiboullah, Amina and Louly, Mohamed Abdellahi},
	title = {Soil Moisture Prediction Based on Satellite Data Using a Novel Deep Learning Model},
	year = {2022},
	journal = {Communications in Computer and Information Science},
	volume = {1589 CCIS},
	pages = {394 – 408},
	doi = {10.1007/978-3-031-08277-1_32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133236865&doi=10.1007%2f978-3-031-08277-1_32&partnerID=40&md5=c236de132a305d1cc31ecb4090c70992},
	abstract = {Predicting soil moisture plays a key role in precision agriculture development and wildfires prevention. In this paper, we designed and implemented a novel deep learning architecture to predict soil moisture content (SMC) from satellite images using vegetation index (NDVI). The architecture combines a set of U-Net semantic segmentation model with a sequence-to-sequence ConvLSTM layers in order to capture both the pixel-wise satellite image content as well as taking into account the spatial correlation property of SMC. The model was trained on data collected from European Sentinel-2 and NASA SMAP satellites for an agricultural area in the Senegalese-Mauritanian river valley. We deployed the model with an end-to-end ML-Ops pipeline using KServe on Google Cloud platform and Microsoft Azure with a production-ready Json-API. The model shows predictions close to ground truth data with a Mean Absolute Error of 0.0325, a RMSE of 0.0447 and an unbiased RMSE of 0.0435. © 2022, Springer Nature Switzerland AG.},
	author_keywords = {Deep learning; Precision agriculture; Satellite imagery; Soil moisture},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Khan202494,
	author = {Khan, Atiya and Patil, Chandrashekhar H. and Vibhute, Amol D. and Mali, Shankar},
	title = {A U-Net Based Approach for High-Accuracy Land Use Land Cover Classification in Hyperspectral Remote Sensing},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2031},
	pages = {94 – 106},
	doi = {10.1007/978-3-031-53728-8_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186264074&doi=10.1007%2f978-3-031-53728-8_8&partnerID=40&md5=2592cd8c0fd2275cbefc87597d782a3f},
	abstract = {Deep learning has been demonstrated to have significant potential in the classification of hyperspectral images (HSI). Hyperspectral imaging has gained more recognition in recent years in the area of computer vision research. Its potential to handle remote sensing-related issues, particularly those related to the agricultural sector, has led to its rising popularity. Due to the significant spectral band redundancy, the small number of training samples, and the non-linear relationship between spatial position and spectral bands, HSI classification is a challenging task. Therefore, we propose machine and deep learning-based models to classify the land features with the highest accuracy. Effective bands have been discovered by applying principal component analysis (PCA) to minimize the dimensionality of hyperspectral images. In this work, we evaluate the land use and land cover (LULC) classification efficiency of three different algorithms like Support Vector Machine (SVM), Spectral Angle Mapper (SAM) and U-Convolutional Neural Network (U-net).Using Hyperion images, we demonstrate and evaluate the findings from each method. In this work, we apply deep convolutional neural networks for the classification of high-quality remote sensing images. Semantic image segmentation is used for U-Net frameworks. In the Nagpur district, we map the existence or lack of vegetation and agricultural land using the U-net neural network architecture for Hyperion images. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Convolution Neural Network; Deep Learning; hyperspectral imagery; U-net; vegetation classification},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Yuan2020465,
	author = {Yuan, Jingwen and Wu, Chen and Du, Bo and Zhang, Liangpei and Wang, Shugen},
	title = {Analysis of landscape pattern on urban land use based on GF-5 hyperspectral data; [高分五号高光谱遥感影像的城市土地利用景观格局分析]},
	year = {2020},
	journal = {Yaogan Xuebao/Journal of Remote Sensing},
	volume = {24},
	number = {4},
	pages = {465 – 478},
	doi = {10.11834/jrs.20209252},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084990552&doi=10.11834%2fjrs.20209252&partnerID=40&md5=f93501a355980074bce08218c9c22ba2},
	abstract = {With the increasing of population, the world has experienced unprecedented urbanization, especially in developing countries. Rapid urbanization inevitably brings serious ecological and environmental problems. In order to better monitor the urbanization process of mega-cities, this study, which focus on north of the Yangtze river of Wuhan metropolitan region, attempts aimed to analyze the urban landscape pattern characteristics and the trends of urbanization trends by using the north of the Yangtze River of Wuhan metropolitan region as the case study. In this study, we proposed a modified Spectral-Spatial Unified Network (SSUN-)-CRF method, which revised from a Spectral-Spatial Unified Networks classification (SSUN) method, based on deep-learning, to extract the urban land use classification on a fine scale and recover detailed structure with GF-5 hyperspectral data in 2018. Then, we assessed seven key landscape pattern indices to understand the landscape pattern features of seven regions in Wuhan, which are separated into main urban area and suburban area. Then, in this paper we built the urban expansion model, from class metrics to landscape metrics. Index). Wuhan shows the stable and diverse landscape ecological with balanced land use distribution. What's more, after using moving window to evaluate the state of Wuhan's urbanization, it is clear to see the tendency in line from the main urban area to the southeast and southwest of the suburban districts. The main urban area is more evenly distributed and urbanized than the suburban area. Evenness Index) and SHEI (Shannon's Diversity Index), SHDI (Shannon's Dimension), CONTAG (Contagion Fractal Area Index) indices illustrate that Jianghan District has the most evenly distributed commercial area, and has the center of business in Wuhan. While, the commercial area in the suburban district is less and concentrated. (3) On the landscape metrics level: We choose 4 indices to analysis the landscape in Wuhan including PAFRAC (Perimeter The resulst show that: (1) The SSUN-CRF classification algorithm can achieve as little loss of spectral information as possible while taking into account spatial information. Our method can effectively achieve edge refinement and overcome the misclassification of semantic segmentation. The Overall Accuracy (OA) and Kappa were higher than 0.9048 and 0.8807, respectively. (2) According to the landscape analysis, on the class metrics level: the PLAND (Percentage of Landscape) indices of different classes in different districts demonstrate that Wuhan has abundant water resource, the main urban area of Wuhan is more urbanized than that of suburban area. Comparing three kinds of residential areas, Residential Two is the principal part with high-rise buildings. It indicate that Wuhan has a higher per capita living standard. However, Hanyang District develops slower than other main urban areas with the problem of "villages in the city". Furthermore, the advantages of agriculture and water area in the suburban area are obvious, the ecological environment is good, but the urbanization degree is low. The the ecological virescence of suburban area needs to be improved. The PD (Patch Density) and AI (Aggregation The results of this research of serve as guide for the overall development plan, optimizing land use optimization, and sustainable development construction in Wuhan. What's more, this model can further provide decision-making reference for the development of the Yangtze River Economic Belt and the "Yangtze River Spindle." © 2020, Science Press. All right reserved.},
	author_keywords = {Deep learning; Fragstats; Fully connected conditional random field; GF-5 hyperspectral image; Land use; Landscape pattern; Remote sensing; Urbanization; Wuhan},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; All Open Access, Bronze Open Access}
}

@ARTICLE{Samarin20201,
	author = {Samarin, Maxim and Zweifel, Lauren and Roth, Volker and Alewell, Christine},
	title = {Identifying soil erosion processes in alpine grasslands on aerial imagery with a u-net convolutional neural network},
	year = {2020},
	journal = {Remote Sensing},
	volume = {12},
	number = {24},
	pages = {1 – 21},
	doi = {10.3390/rs12244149},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098257991&doi=10.3390%2frs12244149&partnerID=40&md5=be099faf73f5d27279ca8fbdeb91b312},
	abstract = {Erosion in alpine grasslands is a major threat to ecosystem services of alpine soils. Natural causes for the occurrence of soil erosion are steep topography and prevailing climate conditions in combination with soil fragility. To increase our understanding of ongoing erosion processes and support sustainable land-use management, there is a need to acquire detailed information on spatial occurrence and temporal trends. Existing approaches to identify these trends are typically laborious, have lack of transferability to other regions, and are consequently only applicable to smaller regions. In order to overcome these limitations and create a sophisticated erosion monitoring tool capable of large-scale analysis, we developed a model based on U-Net, a fully convolutional neural network, to map different erosion processes on high-resolution aerial images (RGB, 0.25–0.5 m). U-Net was trained on a high-quality data set consisting of labeled erosion sites mapped with object-based image analysis (OBIA) for the Urseren Valley (Central Swiss Alps) for five aerial images (16 year period). We used the U-Net model to map the same study area and conduct quality assessments based on a held-out test region and a temporal transferability test on new images. Erosion classes are assigned according to their type (shallow landslide and sites with reduced vegetation affected by sheet erosion) or land-use impacts (livestock trails and larger management affected areas). We show that results obtained by OBIA and U-Net follow similar linear trends for the 16 year study period, exhibiting increases in total degraded area of 167% and 201%, respectively. Segmentations of eroded sites are generally in good agreement, but also display method-specific differences, which lead to an overall precision of 73%, a recall of 84%, and a F1-score of 78%. Our results show that U-Net is transferable to spatially (within our study area) and temporally unseen data (data from new years) and is therefore a method suitable to efficiently and successfully capture the temporal trends and spatial heterogeneity of degradation in alpine grasslands. Additionally, U-Net is a powerful and robust tool to map erosion sites in a predictive manner utilising large amounts of new aerial imagery. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Deep learning; Erosion mapping; Landslides; Livestock trails; Object-based image analysis; Remote sensing; Semantic segmentation; Sheet erosion},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Zamanoglu2023,
	author = {Zamanoglu, Esref Samil and Erbay, Sergen and Cengil, Emine and Kosunalp, Selahattin and Tumen, Vedat and Demir, Kubilay},
	title = {Land Cover Segmentation using DeepLabV3 and ResNet50},
	year = {2023},
	journal = {CIEES 2023 - IEEE International Conference on Communications, Information, Electronic and Energy Systems},
	doi = {10.1109/CIEES58940.2023.10378824},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183581038&doi=10.1109%2fCIEES58940.2023.10378824&partnerID=40&md5=23d51ebad04bcd6691f56df7d3c5b5c3},
	abstract = {Land cover segmentation has a great importance in various fields, including remote sensing, environmental monitoring, urban planning, agriculture, and natural resource management. It involves a division process of a landscape or region into different classes or categories with respect to the type of land cover in each place. With the recent developments in remote sensing area, high-resolution satellite images can be simply acquired. For an efficient land cover segmentation, in this study, a hybrid approach using deep learning architectures DeepLabV3 and ResNet34 is proposed. The proposed method has been trained and tested using the LandCover AI dataset. As a result, 88.2% F1-score value was obtained with the proposed hybrid approach.  © 2023 IEEE.},
	author_keywords = {artificial intelligence; DeepLabV3; LandCoverAI; ResNet34; semantic segmentation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Zhu2024,
	author = {Zhu, Yu and Pan, Yaozhong and Zhang, Dujuan and Wu, Hanyi and Zhao, Chuanwu},
	title = {A Deep Learning Method for Cultivated Land Parcels' (CLPs) Delineation From High-Resolution Remote Sensing Images With High-Generalization Capability},
	year = {2024},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	volume = {62},
	doi = {10.1109/TGRS.2024.3425673},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198244984&doi=10.1109%2fTGRS.2024.3425673&partnerID=40&md5=dbd70ee80c97cc645a44783795ab31c5},
	abstract = {Accurate cultivated land parcels' (CLPs) information is essential for precision agriculture. Deep learning methods have shown great potential in CLPs' delineation but face challenges in detection accuracy, generalization capability, and parcel optimization quality. This study addresses these challenges by developing a high-generalization multitask detection network coupled with a specialized parcel optimization step. Our detection network integrates boundary and region tasks and designs distinct decoders for each task, employing performance-enhancing modules as well as more balanced training strategies to achieve both accurate semantic recognition and fine-grained boundary depiction. To improve the network's ability to train more generalized models, our study identifies the variations in image hue, landscape surroundings, and boundary granularity as the key factors contributing to generalization degradation and employs color space augmentation (CSA) and attention mechanisms on spatial and hierarchy to enhance the generalization. In addition, the parcel optimization step repairs long-distance boundary breaks and performs object-level fusion of delineated regions and boundaries, resulting in more independent and regular CLP results. Our method was trained and validated on GaoFen-1 images from four diverse regions in China, demonstrating high delineation accuracy. It also maintained stable spatiotemporal generalization across different times and regions. Comprehensive ablation and comparative experiments confirmed the rationale behind our model improvements and demonstrated our method's effectiveness over existing single-task models (SegNet, modified PSPNet (MPSPNet), DeeplabV3+, U-Net, ResU-Net, and R2U-Net) and recent multitask models (ResUNet-a, BSiNet, and SEANet). The implementation of our method is available at https://github.com/BNU-zhu/CLPs-delineation.  © 1980-2012 IEEE.},
	author_keywords = {Agricultural remote sensing; cultivated land parcels (CLPs); deep learning; GaoFen-1 image; semantic segmentation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Hakim2023,
	author = {Hakim, Yofri Furqani and Tsai, Fuan},
	title = {POST-CLASSIFICATION ENHANCEMENT IN THE RESULT OF DEEP LEARNING LAND COVER CLASSIFICATION USING VERY-HIGH RESOLUTION SATELLITE IMAGERY},
	year = {2023},
	journal = {44th Asian Conference on Remote Sensing, ACRS 2023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191253836&partnerID=40&md5=73a470389c7168a6499fd782362cda2a},
	abstract = {Land cover is one of the fundamental data utilized in spatial analysis for a range of applications, including climate, environment, natural resources, agriculture, forestry, planning, health, and even social issues. The demand for land cover data is diverse, ranging from global scale, regional scale, and detailed scale. Furthermore, data updates also become a necessity for users. The current trend is the requirement for more accurate and up-to-date land cover data. The growing demand for accurate and up-to-date land cover data is in sync with improvements in satellite imagery data acquisition technology, which now offers improved spatial resolution and more effective satellite imagery data processing. Satellite imagery data processing technology is also growing rapidly with the advance of artificial intelligence for semantic classification or segmentation. This research uses a deep learning approach to classify land cover on Pleiades very high-resolution satellite imagery. A post-classification enhancement is also carried out to improve the consistency and accuracy of the deep learning classification results. The preliminary research results show that post-classification enhancement with the algorithms proposed in this study can increase the accuracy of classification results using deep learning-based approaches by approximately 2%. The original Overall Accuracy and Kappa of the deep learning classification results were 0.84 and 0.79. After the post-classification enhancement process, the Overall Accuracy and Kappa values increased to 0.86 and 0.81. © 2023 ACRS. All Rights Reserved.},
	author_keywords = {Deep Learning; Image Morphology; Land Cover Classification; Post-Classification Enhancement; Semantic Segmentation; U-Net},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Noureldeen20243601,
	author = {Noureldeen, Ahmed and Wahed, Mohamed E.},
	title = {Enhanced building footprint extraction from satellite imagery using Mask R-CNN and PointRend},
	year = {2024},
	journal = {Bulletin of Electrical Engineering and Informatics},
	volume = {13},
	number = {5},
	pages = {3601 – 3608},
	doi = {10.11591/eei.v13i5.7443},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200388766&doi=10.11591%2feei.v13i5.7443&partnerID=40&md5=0e82667be9a324904069638e7cf3db7f},
	abstract = {The extraction of building footprints from aerial photos and satellite imagery plays a crucial role in change detection, urban development, and detecting encroachments on agricultural land. Deep neural networks offer the capability of extracting features and provide accurate methods for detecting and extracting building footprints from satellite imagery. Image segmentation, the process of dividing an image into coherent parts, can be accomplished using two types: semantic segmentation and instance segmentation. Convolutional neural networks (CNN) are commonly used for both instance and semantic segmentation tasks. In this paper, we propose a hybrid approach to extracting building footprints from low-resolution satellite imagery using instance segmentation techniques. Our analysis demonstrates that the mask region-based CNN (R-CNN) architecture with a ResNet-34 backbone and PointRend head to improve the bounding-boxes and mask prediction achieves the highest performance, as evidenced by various metrics, including an average precision (AP) score of 83.39% and an F-1 score of 85.71%. This approach holds promise for developing automated tools to process satellite imagery, benefiting fields such as agriculture, land use monitoring, and disaster response. © 2024, Institute of Advanced Engineering and Science. All rights reserved.},
	author_keywords = {Artificial intelligence; Building footprint extraction; Convolutional neural network; Deep learning; Satellite imagery},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Safarov2022,
	author = {Safarov, Furkat and Temurbek, Kuchkorov and Jamoljon, Djumanov and Temur, Ochilov and Chedjou, Jean Chamberlain and Abdusalomov, Akmalbek Bobomirzaevich and Cho, Young-Im},
	title = {Improved Agricultural Field Segmentation in Satellite Imagery Using TL-ResUNet Architecture},
	year = {2022},
	journal = {Sensors},
	volume = {22},
	number = {24},
	doi = {10.3390/s22249784},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144482570&doi=10.3390%2fs22249784&partnerID=40&md5=70c756be98da911cb9033c1b142ac200},
	abstract = {Currently, there is a growing population around the world, and this is particularly true in developing countries, where food security is becoming a major problem. Therefore, agricultural land monitoring, land use classification and analysis, and achieving high yields through efficient land use are important research topics in precision agriculture. Deep learning-based algorithms for the classification of satellite images provide more reliable and accurate results than traditional classification algorithms. In this study, we propose a transfer learning based residual UNet architecture (TL-ResUNet) model, which is a semantic segmentation deep neural network model of land cover classification and segmentation using satellite images. The proposed model combines the strengths of residual network, transfer learning, and UNet architecture. We tested the model on public datasets such as DeepGlobe, and the results showed that our proposed model outperforms the classic models initiated with random weights and pre-trained ImageNet coefficients. The TL-ResUNet model outperforms other models on several metrics commonly used as accuracy and performance measures for semantic segmentation tasks. Particularly, we obtained an IoU score of 0.81 on the validation subset of the DeepGlobe dataset for the TL-ResUNet model. © 2022 by the authors.},
	author_keywords = {agriculture; deep learning; image segmentation; satellite imagery; transfer learning; UNet architecture},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 32; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Xue2023,
	author = {Xue, Yingshan and Jiang, Yonghua and Wang, Chengjun and Wu, Kaiwen and Zhang, Xiaoxiao and Liu, Weiling},
	title = {Multi-scale Residual Spatial-Spectral Attention Longan-Litchi Extraction Network for Cultivated Land Non-grain Monitoring},
	year = {2023},
	journal = {2023 11th International Conference on Agro-Geoinformatics, Agro-Geoinformatics 2023},
	doi = {10.1109/Agro-Geoinformatics59224.2023.10233306},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172244617&doi=10.1109%2fAgro-Geoinformatics59224.2023.10233306&partnerID=40&md5=3ee6e44cebbfec256537e3f345c80eb8},
	abstract = {With the continuous development of remote sensing earth observation technology, the acquisition of remote sensing data has become more convenient, and it has been widely used in fields such as agricultural resource investigation, disaster monitoring, and agricultural information management. Hyperspectral imagery has the characteristics of 'unity of maps and spectra', wide wavelength range, large number of bands, complete spectral curves and rich information, which can provide more detailed spectral information for earth observation. It is also of great significance to the development of precision agriculture. Quickly and accurately sensing and predicting changes in land types within agricultural land, cultivated land planting conditions and changes, and improving the ability to dynamically monitor cultivated land protection are the basis for ensuring food security. Planting commercial crops on cultivated land is one of the cases of non-grain conversion of cultivated land, and it is also a problem that needs to be monitored. The extraction of economic crops by means of remote sensing is of great significance to the monitoring of non-grain conversion of cultivated land. At present, there are problems of misclassification between cultivated land and garden land. The identification accuracy of crops and economic crops is not high, which directly affects the effectiveness of refined management of cultivated land protection. As a common economic crop, litchi and longan are widely planted on cultivated land, resulting in the non-grain phenomenon of cultivated land. However, there are few related studies on the extraction of litchi and longan. This paper chooses litchi and longan as the extraction object to study the above problems. In this paper, we propose a multi-scale residual spatial-spectral attention longan-lychee extraction network for hyperspectral imagery. The network first uses the idea of feature pyramids to extract image features under different receptive fields by using convolution kernels of different sizes. Secondly, the fused multi-scale features are screened through a spatial-spectral enhanced attention module, highlighting the spectral features with strong representation and high discrimination that are effective for classification results. Finally, a residual structure is introduced to optimize model training and convergence. Guangdong is one of the most important production areas of litchi and longan in China, ranking first in the country in both area and output. In this paper, Maoming City, Guangdong Province is used as the experimental area for research, and the hyperspectral image of Zhuhai-1 satellite is used as the experimental data. The experimental results show that the method in this paper has certain advantages in the extraction of litchi and longan, which can improve the efficiency and accuracy of longan and litchi extraction, and provide important data and technical support for the monitoring of cultivated land non-grain.  © 2023 IEEE.},
	author_keywords = {deep learning; economic crops extraction; hyperspectral imagery; non-grain; remote sensing; semantic segmentation; spatial context information},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Liu2022,
	author = {Liu, Zhenzhen and Li, Ning and Wang, Lijun and Zhu, Jun and Qin, Fen},
	title = {A multi-angle comprehensive solution based on deep learning to extract cultivated land information from high-resolution remote sensing images},
	year = {2022},
	journal = {Ecological Indicators},
	volume = {141},
	doi = {10.1016/j.ecolind.2022.108961},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132876922&doi=10.1016%2fj.ecolind.2022.108961&partnerID=40&md5=077015962a70008c672fee23d1b14794},
	abstract = {Accurate acquisition of cultivated land area and location information is of great significance to agricultural management, agro-ecological environment monitoring, and national food security. The rapid development of deep learning technology provides a new way to extract cultivated land information. However, there are many parameters involved in deep learning, so it is time-consuming to find the optimal parameters. In order to simplify the complex parameter tuning process and explore the main parameters that affect the classification accuracy of deep learning, this study uses Gaofen-2 images as data support and based on U-Net semantic segmentation model to carry out an experiment of cultivated land extraction in Henan Province, China. This study designs model training in different scenarios based on four bands(near-infrared (Nir), red, green, and blue), three backbone models, and six patch sizes (pixel resolution), and analyzes the training model and classification results from multiple perspectives such as model training time, sample size, epoch, and classification categories and quantity. After analysis and evaluation, we conducted cultivated land extraction experiments in three years and different phenological periods, and finally tested the performance of U-Net, PSPNet, Deeplab, and Random Forest in cultivated land extraction. The results show that: (1) the patch size in the model has the greatest influence on the classification accuracy, which is affected by image resolution, geographic objects and batch size. When the patch size was smaller than 112 × 112 pixels, the model recall and F1 decreased substantially, with a decrease of 23.91% and 22.64%, respectively. (2) For U-Net model, after setting reasonable band combination, backbone model, patch size, epoch and sample category, the segmentation and classification accuracy of predicted results increased by 3.27% (Intersection over Union, IoU), 2.62%(overall accuracy, OA), 3.89%(F1) and 7.89%(Kappa) on average. (3) We also determined the optimal band combination (Nir, Red, and Green), patch size (224 × 224 pixels), and backbone (Resnet34) for cultivated land extraction from Gaofen-2 images. The appropriate patch size of cultivated land extraction in the study is between 224 × 224 and 256 × 256 pixels. (4) For cultivated land extraction, relying only on binary classification is not as effective as multi-classification. © 2022 The Authors},
	author_keywords = {Cultivated land extraction; Deep learning; Gaofen-2; High-resolution remote sensing imagery; U-Net},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; All Open Access, Gold Open Access}
}